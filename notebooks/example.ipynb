{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a5d56e3-6834-41f6-8ebd-b356b19ddb4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 16:55:35.720264: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-25 16:55:35.720324: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-25 16:55:35.721394: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-25 16:55:35.727010: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-25 16:55:36.809007: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: Found GPU: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 16:55:39.437305: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-06-25 16:55:39.437916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 46872 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:81:00.0, compute capability: 8.6\n",
      "2024-06-25 16:55:39.441303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 46872 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:81:00.0, compute capability: 8.6\n",
      "2024-06-25 16:55:41.168700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46872 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:81:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
    "    print('WARNING: GPU device not found.')\n",
    "else:\n",
    "    print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "import sys\n",
    "# Append root path \n",
    "sys.path.append(\"../\")\n",
    "from data.preprocessing import dataset_preprocessing\n",
    "import pickle\n",
    "\n",
    "from model.mixed_effects import *\n",
    "from utils.utils import *\n",
    "from utils.fe_models import get_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc0edaa7-892d-49ef-be2d-659ca35a498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Append root path \n",
    "sys.path.append(\"../\")\n",
    "from data.preprocessing import dataset_preprocessing\n",
    "import pickle\n",
    "\n",
    "dataset_name = \"churn\"\n",
    "target = \"binary\"\n",
    "mode = \"cv\"\n",
    "RS = 42\n",
    "hct = 10\n",
    "test_ratio=0.1\n",
    "val_ratio=0.1\n",
    "folds = 5\n",
    "\n",
    "# Attention: preprocessing script is meant to be executed from the notebooks directory\n",
    "dataset_preprocessing.process_dataset(dataset_name=dataset_name, target=target, \n",
    "                                      mode=mode, RS=RS, hct=hct, \n",
    "                                      test_ratio=test_ratio, val_ratio=val_ratio, \n",
    "                                      folds=folds)\n",
    "data_path = f\"{mode}_RS{RS}_hct{hct}_{folds}folds\"\n",
    "\n",
    "with open(f\"../data/prepared/{dataset_name}/{data_path}/data_dict.pickle\", 'rb') as handle:\n",
    "    data_dict = pickle.load(handle)\n",
    "\n",
    "fold_num = 0\n",
    "x_cols = data_dict[f\"X_train_{fold_num}\"].columns\n",
    "X_train = data_dict[f\"X_train_{fold_num}\"]\n",
    "Z_train = data_dict[f\"Z_train_{fold_num}\"]\n",
    "y_train = data_dict[f\"y_train_{fold_num}\"]\n",
    "\n",
    "X_val = data_dict[f\"X_val_{fold_num}\"]\n",
    "Z_val = data_dict[f\"Z_val_{fold_num}\"]\n",
    "y_val = data_dict[f\"y_val_{fold_num}\"]\n",
    "\n",
    "X_test = data_dict[f\"X_test_{fold_num}\"]\n",
    "Z_test = data_dict[f\"Z_test_{fold_num}\"]\n",
    "y_test = data_dict[f\"y_test_{fold_num}\"]\n",
    "\n",
    "qs = np.max([tf.reduce_max(Z_train, axis=0),tf.reduce_max(Z_val, axis=0),tf.reduce_max(Z_test, axis=0)],axis=0)+1\n",
    "\n",
    "X_train = tf.convert_to_tensor(X_train)\n",
    "Z_train = tf.convert_to_tensor(Z_train,dtype=tf.int32)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "\n",
    "X_val = tf.convert_to_tensor(X_val)\n",
    "Z_val = tf.convert_to_tensor(Z_val,dtype=tf.int32)\n",
    "y_val = tf.convert_to_tensor(y_val)\n",
    "\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "Z_test = tf.convert_to_tensor(Z_test,dtype=tf.int32)\n",
    "y_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfd9f350-3f29-4b22-9dba-8d8a39fb059a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 17:01:26.783262: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Start sampling for epoch 1 of training\n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 2s 46ms/step - me_loss: 0.7702 - me_loss_val: 0.7543 - fe_loss: 0.5995 - fe_loss_val: 0.5971 - me_auc: 0.4605 - me_auc_val: 0.4520 - fe_auc: 0.5526 - fe_auc_val: 0.5377 - stds: 0.8128 - acceptance_rate: 0.0000e+00\n",
      "Adapt step size to 0.05000000074505806\n",
      "\n",
      " Start sampling for epoch 2 of training\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.7092 - me_loss_val: 0.6947 - fe_loss: 0.5438 - fe_loss_val: 0.5427 - me_auc: 0.4719 - me_auc_val: 0.4648 - fe_auc: 0.6040 - fe_auc_val: 0.5946 - stds: 0.8128 - acceptance_rate: 0.0000e+00\n",
      "Adapt step size to 0.02500000037252903\n",
      "\n",
      " Start sampling for epoch 3 of training\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.6677 - me_loss_val: 0.6538 - fe_loss: 0.5078 - fe_loss_val: 0.5071 - me_auc: 0.4731 - me_auc_val: 0.4657 - fe_auc: 0.6179 - fe_auc_val: 0.5968 - stds: 0.8128 - acceptance_rate: 0.0000e+00\n",
      "Adapt step size to 0.012500000186264515\n",
      "\n",
      " Start sampling for epoch 4 of training\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.6343 - me_loss_val: 0.6199 - fe_loss: 0.4803 - fe_loss_val: 0.4795 - me_auc: 0.4726 - me_auc_val: 0.4651 - fe_auc: 0.6175 - fe_auc_val: 0.5864 - stds: 0.8128 - acceptance_rate: 0.0000e+00\n",
      "Adapt step size to 0.0062500000931322575\n",
      "\n",
      " Start sampling for epoch 5 of training\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.6053 - me_loss_val: 0.5895 - fe_loss: 0.4575 - fe_loss_val: 0.4557 - me_auc: 0.4750 - me_auc_val: 0.4703 - fe_auc: 0.6205 - fe_auc_val: 0.5957 - stds: 0.8128 - acceptance_rate: 0.0000e+00\n",
      "Adapt step size to 0.0031250000465661287\n",
      "\n",
      " Start sampling for epoch 6 of training\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.5822 - me_loss_val: 0.5650 - fe_loss: 0.4404 - fe_loss_val: 0.4372 - me_auc: 0.4767 - me_auc_val: 0.4739 - fe_auc: 0.6229 - fe_auc_val: 0.6089 - stds: 0.8128 - acceptance_rate: 0.0000e+00\n",
      "Adapt step size to 0.0015625000232830644\n",
      "\n",
      " Start sampling for epoch 7 of training\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.5128 - me_loss_val: 0.4949 - fe_loss: 0.4278 - fe_loss_val: 0.4241 - me_auc: 0.4928 - me_auc_val: 0.4958 - fe_auc: 0.6338 - fe_auc_val: 0.6208 - stds: 0.6629 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 8 of training\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.4636 - me_loss_val: 0.4466 - fe_loss: 0.4165 - fe_loss_val: 0.4124 - me_auc: 0.5124 - me_auc_val: 0.5196 - fe_auc: 0.6430 - fe_auc_val: 0.6324 - stds: 0.5678 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 9 of training\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.4267 - me_loss_val: 0.4120 - fe_loss: 0.4088 - fe_loss_val: 0.4041 - me_auc: 0.5404 - me_auc_val: 0.5531 - fe_auc: 0.6451 - fe_auc_val: 0.6352 - stds: 0.2949 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 10 of training\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 0s 14ms/step - me_loss: 0.4165 - me_loss_val: 0.4031 - fe_loss: 0.4028 - fe_loss_val: 0.3975 - me_auc: 0.5569 - me_auc_val: 0.5707 - fe_auc: 0.6527 - fe_auc_val: 0.6451 - stds: 0.2171 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 11 of training\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.4048 - me_loss_val: 0.3941 - fe_loss: 0.3987 - fe_loss_val: 0.3940 - me_auc: 0.6049 - me_auc_val: 0.6183 - fe_auc: 0.6610 - fe_auc_val: 0.6495 - stds: 0.2257 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 12 of training\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 0s 14ms/step - me_loss: 0.3975 - me_loss_val: 0.3895 - fe_loss: 0.3942 - fe_loss_val: 0.3897 - me_auc: 0.6464 - me_auc_val: 0.6493 - fe_auc: 0.6753 - fe_auc_val: 0.6617 - stds: 0.2187 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 13 of training\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.3963 - me_loss_val: 0.3890 - fe_loss: 0.3911 - fe_loss_val: 0.3868 - me_auc: 0.6588 - me_auc_val: 0.6561 - fe_auc: 0.6847 - fe_auc_val: 0.6702 - stds: 0.2234 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 14 of training\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.3913 - me_loss_val: 0.3850 - fe_loss: 0.3868 - fe_loss_val: 0.3819 - me_auc: 0.6867 - me_auc_val: 0.6710 - fe_auc: 0.7009 - fe_auc_val: 0.6865 - stds: 0.2343 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 15 of training\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 0s 19ms/step - me_loss: 0.3892 - me_loss_val: 0.3830 - fe_loss: 0.3838 - fe_loss_val: 0.3783 - me_auc: 0.6934 - me_auc_val: 0.6751 - fe_auc: 0.7124 - fe_auc_val: 0.6994 - stds: 0.0919 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 16 of training\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 0s 14ms/step - me_loss: 0.3896 - me_loss_val: 0.3843 - fe_loss: 0.3829 - fe_loss_val: 0.3783 - me_auc: 0.6998 - me_auc_val: 0.6720 - fe_auc: 0.7187 - fe_auc_val: 0.6992 - stds: 0.0843 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 17 of training\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.3876 - me_loss_val: 0.3837 - fe_loss: 0.3816 - fe_loss_val: 0.3779 - me_auc: 0.7069 - me_auc_val: 0.6736 - fe_auc: 0.7262 - fe_auc_val: 0.6986 - stds: 0.0705 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 18 of training\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.3840 - me_loss_val: 0.3811 - fe_loss: 0.3792 - fe_loss_val: 0.3760 - me_auc: 0.7197 - me_auc_val: 0.6796 - fe_auc: 0.7366 - fe_auc_val: 0.7079 - stds: 0.0632 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 19 of training\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 0s 14ms/step - me_loss: 0.3812 - me_loss_val: 0.3799 - fe_loss: 0.3771 - fe_loss_val: 0.3752 - me_auc: 0.7292 - me_auc_val: 0.6838 - fe_auc: 0.7458 - fe_auc_val: 0.7104 - stds: 0.0597 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 20 of training\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 0s 14ms/step - me_loss: 0.3789 - me_loss_val: 0.3783 - fe_loss: 0.3752 - fe_loss_val: 0.3737 - me_auc: 0.7402 - me_auc_val: 0.6870 - fe_auc: 0.7575 - fe_auc_val: 0.7157 - stds: 0.0605 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 21 of training\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.3768 - me_loss_val: 0.3760 - fe_loss: 0.3743 - fe_loss_val: 0.3724 - me_auc: 0.7467 - me_auc_val: 0.6880 - fe_auc: 0.7637 - fe_auc_val: 0.7195 - stds: 0.0618 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 22 of training\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.3739 - me_loss_val: 0.3735 - fe_loss: 0.3728 - fe_loss_val: 0.3710 - me_auc: 0.7545 - me_auc_val: 0.6953 - fe_auc: 0.7695 - fe_auc_val: 0.7243 - stds: 0.0634 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 23 of training\n",
      "Epoch 23/500\n",
      "8/8 [==============================] - 0s 14ms/step - me_loss: 0.3717 - me_loss_val: 0.3715 - fe_loss: 0.3711 - fe_loss_val: 0.3695 - me_auc: 0.7587 - me_auc_val: 0.7056 - fe_auc: 0.7742 - fe_auc_val: 0.7322 - stds: 0.0699 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 24 of training\n",
      "Epoch 24/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.3669 - me_loss_val: 0.3672 - fe_loss: 0.3674 - fe_loss_val: 0.3660 - me_auc: 0.7639 - me_auc_val: 0.7110 - fe_auc: 0.7792 - fe_auc_val: 0.7343 - stds: 0.0723 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 25 of training\n",
      "Epoch 25/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.3651 - me_loss_val: 0.3671 - fe_loss: 0.3663 - fe_loss_val: 0.3664 - me_auc: 0.7768 - me_auc_val: 0.7125 - fe_auc: 0.7908 - fe_auc_val: 0.7382 - stds: 0.0751 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 26 of training\n",
      "Epoch 26/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.3634 - me_loss_val: 0.3658 - fe_loss: 0.3649 - fe_loss_val: 0.3654 - me_auc: 0.7850 - me_auc_val: 0.7113 - fe_auc: 0.8021 - fe_auc_val: 0.7359 - stds: 0.0695 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 27 of training\n",
      "Epoch 27/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.3600 - me_loss_val: 0.3637 - fe_loss: 0.3622 - fe_loss_val: 0.3640 - me_auc: 0.7980 - me_auc_val: 0.7159 - fe_auc: 0.8138 - fe_auc_val: 0.7419 - stds: 0.0731 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 28 of training\n",
      "Epoch 28/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.3574 - me_loss_val: 0.3631 - fe_loss: 0.3606 - fe_loss_val: 0.3643 - me_auc: 0.8116 - me_auc_val: 0.7174 - fe_auc: 0.8271 - fe_auc_val: 0.7448 - stds: 0.0781 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 29 of training\n",
      "Epoch 29/500\n",
      "8/8 [==============================] - 0s 14ms/step - me_loss: 0.3545 - me_loss_val: 0.3602 - fe_loss: 0.3587 - fe_loss_val: 0.3626 - me_auc: 0.8075 - me_auc_val: 0.7185 - fe_auc: 0.8247 - fe_auc_val: 0.7459 - stds: 0.0801 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 30 of training\n",
      "Epoch 30/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.3521 - me_loss_val: 0.3571 - fe_loss: 0.3571 - fe_loss_val: 0.3601 - me_auc: 0.8112 - me_auc_val: 0.7248 - fe_auc: 0.8282 - fe_auc_val: 0.7544 - stds: 0.0869 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 31 of training\n",
      "Epoch 31/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.3496 - me_loss_val: 0.3559 - fe_loss: 0.3551 - fe_loss_val: 0.3592 - me_auc: 0.8136 - me_auc_val: 0.7242 - fe_auc: 0.8311 - fe_auc_val: 0.7507 - stds: 0.0933 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 32 of training\n",
      "Epoch 32/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.3491 - me_loss_val: 0.3577 - fe_loss: 0.3550 - fe_loss_val: 0.3615 - me_auc: 0.8209 - me_auc_val: 0.7222 - fe_auc: 0.8386 - fe_auc_val: 0.7494 - stds: 0.0970 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 33 of training\n",
      "Epoch 33/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.3446 - me_loss_val: 0.3544 - fe_loss: 0.3513 - fe_loss_val: 0.3589 - me_auc: 0.8298 - me_auc_val: 0.7272 - fe_auc: 0.8474 - fe_auc_val: 0.7538 - stds: 0.0966 - acceptance_rate: 0.9475\n",
      "\n",
      " Start sampling for epoch 34 of training\n",
      "Epoch 34/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.3377 - me_loss_val: 0.3486 - fe_loss: 0.3445 - fe_loss_val: 0.3533 - me_auc: 0.8302 - me_auc_val: 0.7352 - fe_auc: 0.8496 - fe_auc_val: 0.7587 - stds: 0.0997 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 35 of training\n",
      "Epoch 35/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.3367 - me_loss_val: 0.3501 - fe_loss: 0.3435 - fe_loss_val: 0.3548 - me_auc: 0.8481 - me_auc_val: 0.7363 - fe_auc: 0.8675 - fe_auc_val: 0.7641 - stds: 0.1083 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 36 of training\n",
      "Epoch 36/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.3346 - me_loss_val: 0.3485 - fe_loss: 0.3412 - fe_loss_val: 0.3530 - me_auc: 0.8537 - me_auc_val: 0.7413 - fe_auc: 0.8716 - fe_auc_val: 0.7684 - stds: 0.1088 - acceptance_rate: 0.8164\n",
      "\n",
      " Start sampling for epoch 37 of training\n",
      "Epoch 37/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.3327 - me_loss_val: 0.3466 - fe_loss: 0.3389 - fe_loss_val: 0.3507 - me_auc: 0.8487 - me_auc_val: 0.7417 - fe_auc: 0.8679 - fe_auc_val: 0.7659 - stds: 0.1186 - acceptance_rate: 0.9579\n",
      "\n",
      " Start sampling for epoch 38 of training\n",
      "Epoch 38/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.3278 - me_loss_val: 0.3427 - fe_loss: 0.3339 - fe_loss_val: 0.3465 - me_auc: 0.8566 - me_auc_val: 0.7484 - fe_auc: 0.8768 - fe_auc_val: 0.7734 - stds: 0.1190 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 39 of training\n",
      "Epoch 39/500\n",
      "8/8 [==============================] - 0s 14ms/step - me_loss: 0.3250 - me_loss_val: 0.3424 - fe_loss: 0.3312 - fe_loss_val: 0.3460 - me_auc: 0.8688 - me_auc_val: 0.7407 - fe_auc: 0.8897 - fe_auc_val: 0.7679 - stds: 0.1186 - acceptance_rate: 0.7425\n",
      "\n",
      " Start sampling for epoch 40 of training\n",
      "Epoch 40/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.3184 - me_loss_val: 0.3379 - fe_loss: 0.3243 - fe_loss_val: 0.3414 - me_auc: 0.8638 - me_auc_val: 0.7377 - fe_auc: 0.8857 - fe_auc_val: 0.7659 - stds: 0.1212 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 41 of training\n",
      "Epoch 41/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.3149 - me_loss_val: 0.3368 - fe_loss: 0.3204 - fe_loss_val: 0.3398 - me_auc: 0.8693 - me_auc_val: 0.7421 - fe_auc: 0.8912 - fe_auc_val: 0.7685 - stds: 0.1306 - acceptance_rate: 0.9475\n",
      "\n",
      " Start sampling for epoch 42 of training\n",
      "Epoch 42/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.3133 - me_loss_val: 0.3378 - fe_loss: 0.3191 - fe_loss_val: 0.3408 - me_auc: 0.8817 - me_auc_val: 0.7426 - fe_auc: 0.9044 - fe_auc_val: 0.7728 - stds: 0.1367 - acceptance_rate: 0.8951\n",
      "\n",
      " Start sampling for epoch 43 of training\n",
      "Epoch 43/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.3150 - me_loss_val: 0.3409 - fe_loss: 0.3215 - fe_loss_val: 0.3444 - me_auc: 0.8865 - me_auc_val: 0.7406 - fe_auc: 0.9064 - fe_auc_val: 0.7735 - stds: 0.1401 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 44 of training\n",
      "Epoch 44/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.3063 - me_loss_val: 0.3315 - fe_loss: 0.3110 - fe_loss_val: 0.3334 - me_auc: 0.8858 - me_auc_val: 0.7485 - fe_auc: 0.9080 - fe_auc_val: 0.7797 - stds: 0.1448 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 45 of training\n",
      "Epoch 45/500\n",
      "8/8 [==============================] - 0s 14ms/step - me_loss: 0.2976 - me_loss_val: 0.3206 - fe_loss: 0.3002 - fe_loss_val: 0.3205 - me_auc: 0.8764 - me_auc_val: 0.7558 - fe_auc: 0.8988 - fe_auc_val: 0.7822 - stds: 0.1404 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 46 of training\n",
      "Epoch 46/500\n",
      "8/8 [==============================] - 0s 14ms/step - me_loss: 0.2980 - me_loss_val: 0.3253 - fe_loss: 0.3005 - fe_loss_val: 0.3248 - me_auc: 0.8962 - me_auc_val: 0.7587 - fe_auc: 0.9181 - fe_auc_val: 0.7879 - stds: 0.1393 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 47 of training\n",
      "Epoch 47/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.2982 - me_loss_val: 0.3296 - fe_loss: 0.3008 - fe_loss_val: 0.3291 - me_auc: 0.9046 - me_auc_val: 0.7507 - fe_auc: 0.9279 - fe_auc_val: 0.7871 - stds: 0.1563 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 48 of training\n",
      "Epoch 48/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.2955 - me_loss_val: 0.3284 - fe_loss: 0.2994 - fe_loss_val: 0.3296 - me_auc: 0.8936 - me_auc_val: 0.7362 - fe_auc: 0.9183 - fe_auc_val: 0.7729 - stds: 0.1551 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 49 of training\n",
      "Epoch 49/500\n",
      "8/8 [==============================] - 0s 14ms/step - me_loss: 0.2926 - me_loss_val: 0.3281 - fe_loss: 0.2968 - fe_loss_val: 0.3302 - me_auc: 0.8916 - me_auc_val: 0.7359 - fe_auc: 0.9170 - fe_auc_val: 0.7724 - stds: 0.1619 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 50 of training\n",
      "Epoch 50/500\n",
      "8/8 [==============================] - 0s 14ms/step - me_loss: 0.2883 - me_loss_val: 0.3268 - fe_loss: 0.2925 - fe_loss_val: 0.3288 - me_auc: 0.9003 - me_auc_val: 0.7344 - fe_auc: 0.9264 - fe_auc_val: 0.7723 - stds: 0.1687 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 51 of training\n",
      "Epoch 51/500\n",
      "8/8 [==============================] - 0s 14ms/step - me_loss: 0.2835 - me_loss_val: 0.3230 - fe_loss: 0.2865 - fe_loss_val: 0.3237 - me_auc: 0.9050 - me_auc_val: 0.7348 - fe_auc: 0.9305 - fe_auc_val: 0.7728 - stds: 0.1760 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 52 of training\n",
      "Epoch 52/500\n",
      "8/8 [==============================] - 0s 14ms/step - me_loss: 0.2810 - me_loss_val: 0.3212 - fe_loss: 0.2827 - fe_loss_val: 0.3205 - me_auc: 0.9124 - me_auc_val: 0.7427 - fe_auc: 0.9378 - fe_auc_val: 0.7821 - stds: 0.1946 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 53 of training\n",
      "Epoch 53/500\n",
      "8/8 [==============================] - 0s 14ms/step - me_loss: 0.2760 - me_loss_val: 0.3162 - fe_loss: 0.2768 - fe_loss_val: 0.3145 - me_auc: 0.9105 - me_auc_val: 0.7435 - fe_auc: 0.9360 - fe_auc_val: 0.7802 - stds: 0.1920 - acceptance_rate: 0.9579\n",
      "\n",
      " Start sampling for epoch 54 of training\n",
      "Epoch 54/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.2735 - me_loss_val: 0.3178 - fe_loss: 0.2741 - fe_loss_val: 0.3155 - me_auc: 0.9225 - me_auc_val: 0.7446 - fe_auc: 0.9482 - fe_auc_val: 0.7841 - stds: 0.2078 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 55 of training\n",
      "Epoch 55/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.2720 - me_loss_val: 0.3209 - fe_loss: 0.2732 - fe_loss_val: 0.3191 - me_auc: 0.9292 - me_auc_val: 0.7403 - fe_auc: 0.9540 - fe_auc_val: 0.7835 - stds: 0.2105 - acceptance_rate: 0.9738\n",
      "\n",
      " Start sampling for epoch 56 of training\n",
      "Epoch 56/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.2683 - me_loss_val: 0.3189 - fe_loss: 0.2682 - fe_loss_val: 0.3161 - me_auc: 0.9266 - me_auc_val: 0.7338 - fe_auc: 0.9532 - fe_auc_val: 0.7728 - stds: 0.2153 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 57 of training\n",
      "Epoch 57/500\n",
      "8/8 [==============================] - 0s 14ms/step - me_loss: 0.2668 - me_loss_val: 0.3172 - fe_loss: 0.2654 - fe_loss_val: 0.3130 - me_auc: 0.9228 - me_auc_val: 0.7344 - fe_auc: 0.9496 - fe_auc_val: 0.7712 - stds: 0.2107 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 58 of training\n",
      "Epoch 58/500\n",
      "8/8 [==============================] - 0s 14ms/step - me_loss: 0.2667 - me_loss_val: 0.3186 - fe_loss: 0.2652 - fe_loss_val: 0.3142 - me_auc: 0.9220 - me_auc_val: 0.7323 - fe_auc: 0.9499 - fe_auc_val: 0.7730 - stds: 0.2227 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 59 of training\n",
      "Epoch 59/500\n",
      "8/8 [==============================] - 0s 14ms/step - me_loss: 0.2667 - me_loss_val: 0.3211 - fe_loss: 0.2647 - fe_loss_val: 0.3164 - me_auc: 0.9297 - me_auc_val: 0.7352 - fe_auc: 0.9568 - fe_auc_val: 0.7796 - stds: 0.2248 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 60 of training\n",
      "Epoch 60/500\n",
      "8/8 [==============================] - 0s 14ms/step - me_loss: 0.2638 - me_loss_val: 0.3216 - fe_loss: 0.2604 - fe_loss_val: 0.3157 - me_auc: 0.9340 - me_auc_val: 0.7371 - fe_auc: 0.9605 - fe_auc_val: 0.7811 - stds: 0.2282 - acceptance_rate: 0.9316\n",
      "\n",
      " Start sampling for epoch 61 of training\n",
      "Epoch 61/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.2606 - me_loss_val: 0.3208 - fe_loss: 0.2571 - fe_loss_val: 0.3144 - me_auc: 0.9415 - me_auc_val: 0.7381 - fe_auc: 0.9675 - fe_auc_val: 0.7839 - stds: 0.2290 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 62 of training\n",
      "Epoch 62/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.2550 - me_loss_val: 0.3181 - fe_loss: 0.2505 - fe_loss_val: 0.3104 - me_auc: 0.9421 - me_auc_val: 0.7359 - fe_auc: 0.9670 - fe_auc_val: 0.7822 - stds: 0.2403 - acceptance_rate: 0.9738\n",
      "\n",
      " Start sampling for epoch 63 of training\n",
      "Epoch 63/500\n",
      "8/8 [==============================] - 0s 14ms/step - me_loss: 0.2506 - me_loss_val: 0.3163 - fe_loss: 0.2459 - fe_loss_val: 0.3081 - me_auc: 0.9459 - me_auc_val: 0.7371 - fe_auc: 0.9697 - fe_auc_val: 0.7797 - stds: 0.2500 - acceptance_rate: 0.9438\n",
      "\n",
      " Start sampling for epoch 64 of training\n",
      "Epoch 64/500\n",
      "8/8 [==============================] - 0s 14ms/step - me_loss: 0.2481 - me_loss_val: 0.3137 - fe_loss: 0.2427 - fe_loss_val: 0.3043 - me_auc: 0.9453 - me_auc_val: 0.7369 - fe_auc: 0.9700 - fe_auc_val: 0.7867 - stds: 0.2720 - acceptance_rate: 0.8798\n",
      "\n",
      " Start sampling for epoch 65 of training\n",
      "Epoch 65/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.2446 - me_loss_val: 0.3120 - fe_loss: 0.2385 - fe_loss_val: 0.3019 - me_auc: 0.9435 - me_auc_val: 0.7391 - fe_auc: 0.9682 - fe_auc_val: 0.7877 - stds: 0.2767 - acceptance_rate: 0.8011\n",
      "\n",
      " Start sampling for epoch 66 of training\n",
      "Epoch 66/500\n",
      "1/8 [==>...........................] - ETA: 0s\n",
      " Early stopping of FE by fe_auc_val at 66 epochs\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.2438 - me_loss_val: 0.3146 - fe_loss: 0.2359 - fe_loss_val: 0.3030 - me_auc: 0.9451 - me_auc_val: 0.7329 - fe_auc: 0.9700 - fe_auc_val: 0.7835 - stds: 0.3046 - acceptance_rate: 1.0000\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(RS)\n",
    "np.random.seed(RS)\n",
    "\n",
    "batch_size=512\n",
    "epochs = 500\n",
    "early_stopping = 20\n",
    "model_name = \"AutoGluon\"\n",
    "loss_use = lambda: tf.keras.losses.BinaryCrossentropy\n",
    "\n",
    "\n",
    "if target == \"categorical\":\n",
    "    n_classes = np.unique(y_train).shape[0]\n",
    "elif target==\"binary\":\n",
    "    n_classes = 1\n",
    "    \n",
    "d = X_train.shape[1] # columns\n",
    "n = X_train.shape[0] # rows\n",
    "num_outputs = n_classes\n",
    "perc_numeric = d/(d+Z_train.shape[1])\n",
    "\n",
    "#             qs = np.max([tf.reduce_max(Z_train, axis=0),tf.reduce_max(Z_val, axis=0),tf.reduce_max(Z_test, axis=0)],axis=0)+1\n",
    "\n",
    "set_seed(RS)\n",
    "\n",
    "fe_model, optimizer = get_model(model_name=model_name, input_size=X_train.shape[1], \n",
    "                                  output_size=num_outputs, \n",
    "                                  target=target, \n",
    "                                  perc_numeric=perc_numeric, RS=RS)\n",
    "\n",
    "initial_stds = np.ones([len(qs),num_outputs]).astype(float).tolist()\n",
    "\n",
    "me_model = MixedEffectsNetwork(X_train, Z_train, y_train, fe_model, \n",
    "                               target=target, qs=qs,\n",
    "                               initial_stds=initial_stds,\n",
    "                              fe_loss_weight=1.,\n",
    "                               mode=\"intercepts\",\n",
    "                               early_stopping_fe=early_stopping,\n",
    "                              )    \n",
    "\n",
    "me_model.compile(\n",
    "    loss_class_me = loss_use()(),\n",
    "    loss_class_fe = loss_use()(),\n",
    "#     metric_class_me = tf.keras.metrics.AUC(multi_label=True, name=\"auc_me\"),\n",
    "#     metric_class_fe = tf.keras.metrics.AUC(multi_label=True, name=\"auc_fe\"),\n",
    "    optimizer=optimizer\n",
    ")\n",
    "\n",
    "mcmc = MCMCSamplingCallback(num_mcmc_samples=1,\n",
    "                            perc_burnin=0.7,\n",
    "                            warm_restart=None,\n",
    "                            num_burnin_steps=1,\n",
    "                            step_size = 0.1#initial_step_size,\n",
    "                       )\n",
    "\n",
    "\n",
    "print_metric = PrintMetrics(X_train, Z_train, y_train, X_val, Z_val, y_val)\n",
    "\n",
    "start = time.time()\n",
    "history = me_model.fit([X_train,Z_train], y_train,\n",
    "             callbacks=[mcmc,\n",
    "                        print_metric,\n",
    "                        tf.keras.callbacks.EarlyStopping(monitor=\"me_auc_val\", patience=early_stopping, mode=\"max\")],\n",
    "             epochs=epochs,\n",
    "             validation_data=[[X_val,Z_val],y_val],\n",
    "            batch_size=batch_size)\n",
    "\n",
    "end = time.time()\n",
    "fit_time_gmenn = round(end-start,2)\n",
    "\n",
    "y_train_pred_gmenn, y_train_pred_gmenn_fe = me_model([X_train,Z_train])\n",
    "y_val_pred_gmenn, y_val_pred_gmenn_fe = me_model([X_val,Z_val])\n",
    "y_test_pred_gmenn, y_test_pred_gmenn_fe = me_model([X_test,Z_test])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5673ce4-ee7e-4fe1-8bc0-64b2ed3d2c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7735776535565972"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test.numpy(),y_test_pred_gmenn.numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcgmenn",
   "language": "python",
   "name": "mcgmenn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
