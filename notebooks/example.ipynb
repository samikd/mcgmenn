{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a5d56e3-6834-41f6-8ebd-b356b19ddb4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 17:39:31.925596: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-25 17:39:31.925701: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-25 17:39:32.006087: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-25 17:39:32.185191: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-25 17:39:33.876163: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-06-25 17:39:36.804578: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-06-25 17:39:36.805016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 46872 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:81:00.0, compute capability: 8.6\n",
      "2024-06-25 17:39:36.810349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 46872 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:81:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: Found GPU: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 17:39:38.908262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46872 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:81:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
    "    print('WARNING: GPU device not found.')\n",
    "else:\n",
    "    print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "import sys\n",
    "# Append root path \n",
    "sys.path.append(\"../\")\n",
    "from data.preprocessing import dataset_preprocessing\n",
    "import pickle\n",
    "\n",
    "from model.mixed_effects import *\n",
    "from utils.utils import *\n",
    "from utils.fe_models import get_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc0edaa7-892d-49ef-be2d-659ca35a498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Append root path \n",
    "sys.path.append(\"../\")\n",
    "from data.preprocessing import dataset_preprocessing\n",
    "import pickle\n",
    "\n",
    "dataset_name = \"churn\"\n",
    "target = \"binary\"\n",
    "mode = \"cv\"\n",
    "RS = 42\n",
    "hct = 10\n",
    "test_ratio=0.1\n",
    "val_ratio=0.1\n",
    "folds = 5\n",
    "\n",
    "# Attention: preprocessing script is meant to be executed from the notebooks directory\n",
    "dataset_preprocessing.process_dataset(dataset_name=dataset_name, target=target, \n",
    "                                      mode=mode, RS=RS, hct=hct, \n",
    "                                      test_ratio=test_ratio, val_ratio=val_ratio, \n",
    "                                      folds=folds)\n",
    "data_path = f\"{mode}_RS{RS}_hct{hct}_{folds}folds\"\n",
    "\n",
    "with open(f\"../data/prepared/{dataset_name}/{data_path}/data_dict.pickle\", 'rb') as handle:\n",
    "    data_dict = pickle.load(handle)\n",
    "\n",
    "fold_num = 0\n",
    "x_cols = data_dict[f\"X_train_{fold_num}\"].columns\n",
    "X_train = data_dict[f\"X_train_{fold_num}\"]\n",
    "Z_train = data_dict[f\"Z_train_{fold_num}\"]\n",
    "y_train = data_dict[f\"y_train_{fold_num}\"]\n",
    "\n",
    "X_val = data_dict[f\"X_val_{fold_num}\"]\n",
    "Z_val = data_dict[f\"Z_val_{fold_num}\"]\n",
    "y_val = data_dict[f\"y_val_{fold_num}\"]\n",
    "\n",
    "X_test = data_dict[f\"X_test_{fold_num}\"]\n",
    "Z_test = data_dict[f\"Z_test_{fold_num}\"]\n",
    "y_test = data_dict[f\"y_test_{fold_num}\"]\n",
    "\n",
    "qs = np.max([tf.reduce_max(Z_train, axis=0),tf.reduce_max(Z_val, axis=0),tf.reduce_max(Z_test, axis=0)],axis=0)+1\n",
    "\n",
    "X_train = tf.convert_to_tensor(X_train)\n",
    "Z_train = tf.convert_to_tensor(Z_train,dtype=tf.int32)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "\n",
    "X_val = tf.convert_to_tensor(X_val)\n",
    "Z_val = tf.convert_to_tensor(Z_val,dtype=tf.int32)\n",
    "y_val = tf.convert_to_tensor(y_val)\n",
    "\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "Z_test = tf.convert_to_tensor(Z_test,dtype=tf.int32)\n",
    "y_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfd9f350-3f29-4b22-9dba-8d8a39fb059a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 17:39:42.905570: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Start sampling for epoch 1 of training\n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 2s 49ms/step - me_loss: 0.7702 - me_loss_val: 0.7543 - fe_loss: 0.5995 - fe_loss_val: 0.5971 - me_auc: 0.4605 - me_auc_val: 0.4520 - fe_auc: 0.5526 - fe_auc_val: 0.5377 - stds: 0.8128 - acceptance_rate: 0.0000e+00\n",
      "Adapt step size to 0.05000000074505806\n",
      "\n",
      " Start sampling for epoch 2 of training\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.7092 - me_loss_val: 0.6947 - fe_loss: 0.5438 - fe_loss_val: 0.5427 - me_auc: 0.4719 - me_auc_val: 0.4648 - fe_auc: 0.6040 - fe_auc_val: 0.5946 - stds: 0.8128 - acceptance_rate: 0.0000e+00\n",
      "Adapt step size to 0.02500000037252903\n",
      "\n",
      " Start sampling for epoch 3 of training\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.6677 - me_loss_val: 0.6538 - fe_loss: 0.5078 - fe_loss_val: 0.5071 - me_auc: 0.4731 - me_auc_val: 0.4657 - fe_auc: 0.6179 - fe_auc_val: 0.5968 - stds: 0.8128 - acceptance_rate: 0.0000e+00\n",
      "Adapt step size to 0.012500000186264515\n",
      "\n",
      " Start sampling for epoch 4 of training\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.6343 - me_loss_val: 0.6199 - fe_loss: 0.4803 - fe_loss_val: 0.4795 - me_auc: 0.4726 - me_auc_val: 0.4651 - fe_auc: 0.6175 - fe_auc_val: 0.5864 - stds: 0.8128 - acceptance_rate: 0.0000e+00\n",
      "Adapt step size to 0.0062500000931322575\n",
      "\n",
      " Start sampling for epoch 5 of training\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.6053 - me_loss_val: 0.5895 - fe_loss: 0.4575 - fe_loss_val: 0.4557 - me_auc: 0.4750 - me_auc_val: 0.4703 - fe_auc: 0.6204 - fe_auc_val: 0.5958 - stds: 0.8128 - acceptance_rate: 0.0000e+00\n",
      "Adapt step size to 0.0031250000465661287\n",
      "\n",
      " Start sampling for epoch 6 of training\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.5822 - me_loss_val: 0.5650 - fe_loss: 0.4404 - fe_loss_val: 0.4372 - me_auc: 0.4767 - me_auc_val: 0.4739 - fe_auc: 0.6229 - fe_auc_val: 0.6089 - stds: 0.8128 - acceptance_rate: 0.0000e+00\n",
      "Adapt step size to 0.0015625000232830644\n",
      "\n",
      " Start sampling for epoch 7 of training\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.5128 - me_loss_val: 0.4949 - fe_loss: 0.4278 - fe_loss_val: 0.4241 - me_auc: 0.4928 - me_auc_val: 0.4958 - fe_auc: 0.6338 - fe_auc_val: 0.6208 - stds: 0.6629 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 8 of training\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.4636 - me_loss_val: 0.4466 - fe_loss: 0.4165 - fe_loss_val: 0.4124 - me_auc: 0.5124 - me_auc_val: 0.5196 - fe_auc: 0.6430 - fe_auc_val: 0.6324 - stds: 0.5678 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 9 of training\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.4267 - me_loss_val: 0.4120 - fe_loss: 0.4088 - fe_loss_val: 0.4041 - me_auc: 0.5404 - me_auc_val: 0.5531 - fe_auc: 0.6451 - fe_auc_val: 0.6352 - stds: 0.2949 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 10 of training\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.4165 - me_loss_val: 0.4031 - fe_loss: 0.4028 - fe_loss_val: 0.3975 - me_auc: 0.5570 - me_auc_val: 0.5707 - fe_auc: 0.6527 - fe_auc_val: 0.6451 - stds: 0.2172 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 11 of training\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.4048 - me_loss_val: 0.3941 - fe_loss: 0.3987 - fe_loss_val: 0.3940 - me_auc: 0.6049 - me_auc_val: 0.6183 - fe_auc: 0.6610 - fe_auc_val: 0.6495 - stds: 0.2257 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 12 of training\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.3975 - me_loss_val: 0.3895 - fe_loss: 0.3942 - fe_loss_val: 0.3897 - me_auc: 0.6464 - me_auc_val: 0.6493 - fe_auc: 0.6753 - fe_auc_val: 0.6617 - stds: 0.2187 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 13 of training\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.3963 - me_loss_val: 0.3890 - fe_loss: 0.3911 - fe_loss_val: 0.3868 - me_auc: 0.6588 - me_auc_val: 0.6561 - fe_auc: 0.6847 - fe_auc_val: 0.6702 - stds: 0.2234 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 14 of training\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.3913 - me_loss_val: 0.3850 - fe_loss: 0.3868 - fe_loss_val: 0.3819 - me_auc: 0.6866 - me_auc_val: 0.6710 - fe_auc: 0.7009 - fe_auc_val: 0.6865 - stds: 0.2343 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 15 of training\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.3892 - me_loss_val: 0.3830 - fe_loss: 0.3838 - fe_loss_val: 0.3783 - me_auc: 0.6935 - me_auc_val: 0.6750 - fe_auc: 0.7123 - fe_auc_val: 0.6993 - stds: 0.0919 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 16 of training\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.3896 - me_loss_val: 0.3843 - fe_loss: 0.3829 - fe_loss_val: 0.3783 - me_auc: 0.6997 - me_auc_val: 0.6720 - fe_auc: 0.7185 - fe_auc_val: 0.6994 - stds: 0.0843 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 17 of training\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.3876 - me_loss_val: 0.3837 - fe_loss: 0.3817 - fe_loss_val: 0.3779 - me_auc: 0.7072 - me_auc_val: 0.6736 - fe_auc: 0.7261 - fe_auc_val: 0.6984 - stds: 0.0705 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 18 of training\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.3840 - me_loss_val: 0.3811 - fe_loss: 0.3792 - fe_loss_val: 0.3760 - me_auc: 0.7199 - me_auc_val: 0.6798 - fe_auc: 0.7366 - fe_auc_val: 0.7077 - stds: 0.0632 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 19 of training\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.3812 - me_loss_val: 0.3799 - fe_loss: 0.3771 - fe_loss_val: 0.3752 - me_auc: 0.7294 - me_auc_val: 0.6833 - fe_auc: 0.7464 - fe_auc_val: 0.7110 - stds: 0.0597 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 20 of training\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.3789 - me_loss_val: 0.3783 - fe_loss: 0.3752 - fe_loss_val: 0.3737 - me_auc: 0.7405 - me_auc_val: 0.6861 - fe_auc: 0.7572 - fe_auc_val: 0.7156 - stds: 0.0605 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 21 of training\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.3768 - me_loss_val: 0.3760 - fe_loss: 0.3743 - fe_loss_val: 0.3724 - me_auc: 0.7469 - me_auc_val: 0.6882 - fe_auc: 0.7638 - fe_auc_val: 0.7194 - stds: 0.0618 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 22 of training\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.3739 - me_loss_val: 0.3736 - fe_loss: 0.3729 - fe_loss_val: 0.3710 - me_auc: 0.7544 - me_auc_val: 0.6954 - fe_auc: 0.7695 - fe_auc_val: 0.7225 - stds: 0.0635 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 23 of training\n",
      "Epoch 23/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.3716 - me_loss_val: 0.3715 - fe_loss: 0.3711 - fe_loss_val: 0.3695 - me_auc: 0.7584 - me_auc_val: 0.7055 - fe_auc: 0.7735 - fe_auc_val: 0.7320 - stds: 0.0700 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 24 of training\n",
      "Epoch 24/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.3669 - me_loss_val: 0.3672 - fe_loss: 0.3674 - fe_loss_val: 0.3661 - me_auc: 0.7645 - me_auc_val: 0.7119 - fe_auc: 0.7790 - fe_auc_val: 0.7343 - stds: 0.0717 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 25 of training\n",
      "Epoch 25/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.3651 - me_loss_val: 0.3673 - fe_loss: 0.3664 - fe_loss_val: 0.3667 - me_auc: 0.7769 - me_auc_val: 0.7137 - fe_auc: 0.7912 - fe_auc_val: 0.7375 - stds: 0.0791 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 26 of training\n",
      "Epoch 26/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.3634 - me_loss_val: 0.3660 - fe_loss: 0.3650 - fe_loss_val: 0.3656 - me_auc: 0.7855 - me_auc_val: 0.7110 - fe_auc: 0.8022 - fe_auc_val: 0.7362 - stds: 0.0721 - acceptance_rate: 0.9738\n",
      "\n",
      " Start sampling for epoch 27 of training\n",
      "Epoch 27/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.3600 - me_loss_val: 0.3638 - fe_loss: 0.3622 - fe_loss_val: 0.3641 - me_auc: 0.7983 - me_auc_val: 0.7140 - fe_auc: 0.8144 - fe_auc_val: 0.7406 - stds: 0.0729 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 28 of training\n",
      "Epoch 28/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.3575 - me_loss_val: 0.3633 - fe_loss: 0.3605 - fe_loss_val: 0.3643 - me_auc: 0.8107 - me_auc_val: 0.7162 - fe_auc: 0.8273 - fe_auc_val: 0.7436 - stds: 0.0811 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 29 of training\n",
      "Epoch 29/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.3544 - me_loss_val: 0.3602 - fe_loss: 0.3586 - fe_loss_val: 0.3624 - me_auc: 0.8066 - me_auc_val: 0.7191 - fe_auc: 0.8238 - fe_auc_val: 0.7475 - stds: 0.0849 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 30 of training\n",
      "Epoch 30/500\n",
      "8/8 [==============================] - 0s 19ms/step - me_loss: 0.3521 - me_loss_val: 0.3571 - fe_loss: 0.3571 - fe_loss_val: 0.3600 - me_auc: 0.8100 - me_auc_val: 0.7258 - fe_auc: 0.8272 - fe_auc_val: 0.7547 - stds: 0.0891 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 31 of training\n",
      "Epoch 31/500\n",
      "8/8 [==============================] - 0s 14ms/step - me_loss: 0.3496 - me_loss_val: 0.3557 - fe_loss: 0.3552 - fe_loss_val: 0.3591 - me_auc: 0.8130 - me_auc_val: 0.7262 - fe_auc: 0.8311 - fe_auc_val: 0.7519 - stds: 0.0943 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 32 of training\n",
      "Epoch 32/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.3489 - me_loss_val: 0.3573 - fe_loss: 0.3549 - fe_loss_val: 0.3610 - me_auc: 0.8201 - me_auc_val: 0.7227 - fe_auc: 0.8371 - fe_auc_val: 0.7487 - stds: 0.0986 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 33 of training\n",
      "Epoch 33/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.3445 - me_loss_val: 0.3541 - fe_loss: 0.3512 - fe_loss_val: 0.3586 - me_auc: 0.8288 - me_auc_val: 0.7298 - fe_auc: 0.8466 - fe_auc_val: 0.7528 - stds: 0.0982 - acceptance_rate: 0.8798\n",
      "\n",
      " Start sampling for epoch 34 of training\n",
      "Epoch 34/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.3376 - me_loss_val: 0.3485 - fe_loss: 0.3444 - fe_loss_val: 0.3531 - me_auc: 0.8312 - me_auc_val: 0.7340 - fe_auc: 0.8495 - fe_auc_val: 0.7604 - stds: 0.1021 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 35 of training\n",
      "Epoch 35/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.3365 - me_loss_val: 0.3500 - fe_loss: 0.3434 - fe_loss_val: 0.3548 - me_auc: 0.8486 - me_auc_val: 0.7369 - fe_auc: 0.8672 - fe_auc_val: 0.7660 - stds: 0.1113 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 36 of training\n",
      "Epoch 36/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.3338 - me_loss_val: 0.3479 - fe_loss: 0.3403 - fe_loss_val: 0.3522 - me_auc: 0.8524 - me_auc_val: 0.7418 - fe_auc: 0.8701 - fe_auc_val: 0.7659 - stds: 0.1112 - acceptance_rate: 0.8267\n",
      "\n",
      " Start sampling for epoch 37 of training\n",
      "Epoch 37/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.3316 - me_loss_val: 0.3454 - fe_loss: 0.3370 - fe_loss_val: 0.3487 - me_auc: 0.8468 - me_auc_val: 0.7438 - fe_auc: 0.8649 - fe_auc_val: 0.7654 - stds: 0.1193 - acceptance_rate: 0.9738\n",
      "\n",
      " Start sampling for epoch 38 of training\n",
      "Epoch 38/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.3270 - me_loss_val: 0.3418 - fe_loss: 0.3323 - fe_loss_val: 0.3446 - me_auc: 0.8556 - me_auc_val: 0.7499 - fe_auc: 0.8760 - fe_auc_val: 0.7756 - stds: 0.1199 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 39 of training\n",
      "Epoch 39/500\n",
      "8/8 [==============================] - 0s 19ms/step - me_loss: 0.3250 - me_loss_val: 0.3416 - fe_loss: 0.3306 - fe_loss_val: 0.3445 - me_auc: 0.8662 - me_auc_val: 0.7433 - fe_auc: 0.8875 - fe_auc_val: 0.7740 - stds: 0.1191 - acceptance_rate: 0.8267\n",
      "\n",
      " Start sampling for epoch 40 of training\n",
      "Epoch 40/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.3187 - me_loss_val: 0.3374 - fe_loss: 0.3240 - fe_loss_val: 0.3402 - me_auc: 0.8619 - me_auc_val: 0.7389 - fe_auc: 0.8834 - fe_auc_val: 0.7700 - stds: 0.1234 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 41 of training\n",
      "Epoch 41/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.3151 - me_loss_val: 0.3363 - fe_loss: 0.3201 - fe_loss_val: 0.3387 - me_auc: 0.8672 - me_auc_val: 0.7414 - fe_auc: 0.8890 - fe_auc_val: 0.7718 - stds: 0.1312 - acceptance_rate: 0.8951\n",
      "\n",
      " Start sampling for epoch 42 of training\n",
      "Epoch 42/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.3132 - me_loss_val: 0.3370 - fe_loss: 0.3186 - fe_loss_val: 0.3396 - me_auc: 0.8800 - me_auc_val: 0.7437 - fe_auc: 0.9018 - fe_auc_val: 0.7730 - stds: 0.1372 - acceptance_rate: 0.8267\n",
      "\n",
      " Start sampling for epoch 43 of training\n",
      "Epoch 43/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.3139 - me_loss_val: 0.3393 - fe_loss: 0.3202 - fe_loss_val: 0.3425 - me_auc: 0.8857 - me_auc_val: 0.7437 - fe_auc: 0.9066 - fe_auc_val: 0.7736 - stds: 0.1407 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 44 of training\n",
      "Epoch 44/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.3056 - me_loss_val: 0.3304 - fe_loss: 0.3102 - fe_loss_val: 0.3321 - me_auc: 0.8863 - me_auc_val: 0.7518 - fe_auc: 0.9075 - fe_auc_val: 0.7822 - stds: 0.1449 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 45 of training\n",
      "Epoch 45/500\n",
      "8/8 [==============================] - 0s 18ms/step - me_loss: 0.2965 - me_loss_val: 0.3194 - fe_loss: 0.2991 - fe_loss_val: 0.3191 - me_auc: 0.8773 - me_auc_val: 0.7540 - fe_auc: 0.8994 - fe_auc_val: 0.7796 - stds: 0.1420 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 46 of training\n",
      "Epoch 46/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.2969 - me_loss_val: 0.3231 - fe_loss: 0.2993 - fe_loss_val: 0.3224 - me_auc: 0.8946 - me_auc_val: 0.7577 - fe_auc: 0.9156 - fe_auc_val: 0.7864 - stds: 0.1393 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 47 of training\n",
      "Epoch 47/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.2967 - me_loss_val: 0.3267 - fe_loss: 0.2990 - fe_loss_val: 0.3257 - me_auc: 0.9015 - me_auc_val: 0.7509 - fe_auc: 0.9244 - fe_auc_val: 0.7833 - stds: 0.1562 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 48 of training\n",
      "Epoch 48/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.2942 - me_loss_val: 0.3262 - fe_loss: 0.2967 - fe_loss_val: 0.3257 - me_auc: 0.8928 - me_auc_val: 0.7404 - fe_auc: 0.9169 - fe_auc_val: 0.7775 - stds: 0.1604 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 49 of training\n",
      "Epoch 49/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.2910 - me_loss_val: 0.3261 - fe_loss: 0.2933 - fe_loss_val: 0.3257 - me_auc: 0.8911 - me_auc_val: 0.7396 - fe_auc: 0.9170 - fe_auc_val: 0.7747 - stds: 0.1631 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 50 of training\n",
      "Epoch 50/500\n",
      "8/8 [==============================] - 0s 18ms/step - me_loss: 0.2865 - me_loss_val: 0.3244 - fe_loss: 0.2884 - fe_loss_val: 0.3235 - me_auc: 0.8984 - me_auc_val: 0.7371 - fe_auc: 0.9233 - fe_auc_val: 0.7723 - stds: 0.1712 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 51 of training\n",
      "Epoch 51/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.2832 - me_loss_val: 0.3229 - fe_loss: 0.2845 - fe_loss_val: 0.3212 - me_auc: 0.9061 - me_auc_val: 0.7356 - fe_auc: 0.9313 - fe_auc_val: 0.7727 - stds: 0.1823 - acceptance_rate: 0.9097\n",
      "\n",
      " Start sampling for epoch 52 of training\n",
      "Epoch 52/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.2813 - me_loss_val: 0.3213 - fe_loss: 0.2818 - fe_loss_val: 0.3188 - me_auc: 0.9136 - me_auc_val: 0.7428 - fe_auc: 0.9385 - fe_auc_val: 0.7828 - stds: 0.1870 - acceptance_rate: 0.6844\n",
      "\n",
      " Start sampling for epoch 53 of training\n",
      "Epoch 53/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.2760 - me_loss_val: 0.3156 - fe_loss: 0.2758 - fe_loss_val: 0.3124 - me_auc: 0.9088 - me_auc_val: 0.7446 - fe_auc: 0.9346 - fe_auc_val: 0.7854 - stds: 0.1889 - acceptance_rate: 0.9475\n",
      "\n",
      " Start sampling for epoch 54 of training\n",
      "Epoch 54/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.2729 - me_loss_val: 0.3166 - fe_loss: 0.2725 - fe_loss_val: 0.3128 - me_auc: 0.9204 - me_auc_val: 0.7479 - fe_auc: 0.9450 - fe_auc_val: 0.7883 - stds: 0.2074 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 55 of training\n",
      "Epoch 55/500\n",
      "8/8 [==============================] - 0s 19ms/step - me_loss: 0.2716 - me_loss_val: 0.3199 - fe_loss: 0.2720 - fe_loss_val: 0.3169 - me_auc: 0.9284 - me_auc_val: 0.7426 - fe_auc: 0.9531 - fe_auc_val: 0.7842 - stds: 0.2089 - acceptance_rate: 0.9738\n",
      "\n",
      " Start sampling for epoch 56 of training\n",
      "Epoch 56/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.2686 - me_loss_val: 0.3185 - fe_loss: 0.2677 - fe_loss_val: 0.3143 - me_auc: 0.9260 - me_auc_val: 0.7355 - fe_auc: 0.9518 - fe_auc_val: 0.7759 - stds: 0.2145 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 57 of training\n",
      "Epoch 57/500\n",
      "8/8 [==============================] - 0s 15ms/step - me_loss: 0.2665 - me_loss_val: 0.3158 - fe_loss: 0.2642 - fe_loss_val: 0.3101 - me_auc: 0.9191 - me_auc_val: 0.7346 - fe_auc: 0.9468 - fe_auc_val: 0.7759 - stds: 0.2097 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 58 of training\n",
      "Epoch 58/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.2664 - me_loss_val: 0.3168 - fe_loss: 0.2646 - fe_loss_val: 0.3119 - me_auc: 0.9199 - me_auc_val: 0.7335 - fe_auc: 0.9483 - fe_auc_val: 0.7757 - stds: 0.2130 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 59 of training\n",
      "Epoch 59/500\n",
      "8/8 [==============================] - 0s 19ms/step - me_loss: 0.2661 - me_loss_val: 0.3196 - fe_loss: 0.2640 - fe_loss_val: 0.3147 - me_auc: 0.9290 - me_auc_val: 0.7336 - fe_auc: 0.9563 - fe_auc_val: 0.7772 - stds: 0.2179 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 60 of training\n",
      "Epoch 60/500\n",
      "8/8 [==============================] - 0s 16ms/step - me_loss: 0.2632 - me_loss_val: 0.3211 - fe_loss: 0.2600 - fe_loss_val: 0.3154 - me_auc: 0.9338 - me_auc_val: 0.7296 - fe_auc: 0.9604 - fe_auc_val: 0.7754 - stds: 0.2286 - acceptance_rate: 0.8957\n",
      "\n",
      " Start sampling for epoch 61 of training\n",
      "Epoch 61/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.2602 - me_loss_val: 0.3211 - fe_loss: 0.2567 - fe_loss_val: 0.3151 - me_auc: 0.9411 - me_auc_val: 0.7323 - fe_auc: 0.9665 - fe_auc_val: 0.7771 - stds: 0.2273 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 62 of training\n",
      "Epoch 62/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.2550 - me_loss_val: 0.3197 - fe_loss: 0.2500 - fe_loss_val: 0.3119 - me_auc: 0.9428 - me_auc_val: 0.7356 - fe_auc: 0.9680 - fe_auc_val: 0.7818 - stds: 0.2373 - acceptance_rate: 0.9475\n",
      "\n",
      " Start sampling for epoch 63 of training\n",
      "Epoch 63/500\n",
      "8/8 [==============================] - 0s 18ms/step - me_loss: 0.2509 - me_loss_val: 0.3175 - fe_loss: 0.2457 - fe_loss_val: 0.3091 - me_auc: 0.9452 - me_auc_val: 0.7365 - fe_auc: 0.9699 - fe_auc_val: 0.7822 - stds: 0.2397 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 64 of training\n",
      "Epoch 64/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.2488 - me_loss_val: 0.3148 - fe_loss: 0.2428 - fe_loss_val: 0.3048 - me_auc: 0.9406 - me_auc_val: 0.7364 - fe_auc: 0.9662 - fe_auc_val: 0.7855 - stds: 0.2676 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 65 of training\n",
      "Epoch 65/500\n",
      "8/8 [==============================] - 0s 19ms/step - me_loss: 0.2449 - me_loss_val: 0.3136 - fe_loss: 0.2383 - fe_loss_val: 0.3031 - me_auc: 0.9408 - me_auc_val: 0.7377 - fe_auc: 0.9656 - fe_auc_val: 0.7851 - stds: 0.2790 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 66 of training\n",
      "Epoch 66/500\n",
      "8/8 [==============================] - 0s 17ms/step - me_loss: 0.2448 - me_loss_val: 0.3160 - fe_loss: 0.2371 - fe_loss_val: 0.3051 - me_auc: 0.9447 - me_auc_val: 0.7331 - fe_auc: 0.9708 - fe_auc_val: 0.7876 - stds: 0.2876 - acceptance_rate: 1.0000\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(RS)\n",
    "np.random.seed(RS)\n",
    "\n",
    "batch_size=512\n",
    "epochs = 500\n",
    "early_stopping = 20\n",
    "model_name = \"AutoGluon\"\n",
    "loss_use = lambda: tf.keras.losses.BinaryCrossentropy\n",
    "\n",
    "\n",
    "if target == \"categorical\":\n",
    "    n_classes = np.unique(y_train).shape[0]\n",
    "elif target==\"binary\":\n",
    "    n_classes = 1\n",
    "    \n",
    "d = X_train.shape[1] # columns\n",
    "n = X_train.shape[0] # rows\n",
    "num_outputs = n_classes\n",
    "perc_numeric = d/(d+Z_train.shape[1])\n",
    "\n",
    "#             qs = np.max([tf.reduce_max(Z_train, axis=0),tf.reduce_max(Z_val, axis=0),tf.reduce_max(Z_test, axis=0)],axis=0)+1\n",
    "\n",
    "set_seed(RS)\n",
    "\n",
    "fe_model, optimizer = get_model(model_name=model_name, input_size=X_train.shape[1], \n",
    "                                  output_size=num_outputs, \n",
    "                                  target=target, \n",
    "                                  perc_numeric=perc_numeric, RS=RS)\n",
    "\n",
    "initial_stds = np.ones([len(qs),num_outputs]).astype(float).tolist()\n",
    "\n",
    "me_model = MixedEffectsNetwork(X_train, Z_train, y_train, fe_model, \n",
    "                               target=target, qs=qs,\n",
    "                               initial_stds=initial_stds,\n",
    "                              fe_loss_weight=1.,\n",
    "                               mode=\"intercepts\",\n",
    "                               early_stopping_fe=early_stopping,\n",
    "                              )    \n",
    "\n",
    "me_model.compile(\n",
    "    loss_class_me = loss_use()(),\n",
    "    loss_class_fe = loss_use()(),\n",
    "#     metric_class_me = tf.keras.metrics.AUC(multi_label=True, name=\"auc_me\"),\n",
    "#     metric_class_fe = tf.keras.metrics.AUC(multi_label=True, name=\"auc_fe\"),\n",
    "    optimizer=optimizer\n",
    ")\n",
    "\n",
    "mcmc = MCMCSamplingCallback(num_mcmc_samples=1,\n",
    "                            perc_burnin=0.7,\n",
    "                            warm_restart=None,\n",
    "                            num_burnin_steps=1,\n",
    "                            step_size = 0.1#initial_step_size,\n",
    "                       )\n",
    "\n",
    "\n",
    "print_metric = PrintMetrics(X_train, Z_train, y_train, X_val, Z_val, y_val)\n",
    "\n",
    "start = time.time()\n",
    "history = me_model.fit([X_train,Z_train], y_train,\n",
    "             callbacks=[mcmc,\n",
    "                        print_metric,\n",
    "                        tf.keras.callbacks.EarlyStopping(monitor=\"me_auc_val\", patience=early_stopping, mode=\"max\")],\n",
    "             epochs=epochs,\n",
    "             validation_data=[[X_val,Z_val],y_val],\n",
    "            batch_size=batch_size)\n",
    "\n",
    "end = time.time()\n",
    "fit_time_gmenn = round(end-start,2)\n",
    "\n",
    "y_train_pred_gmenn, y_train_pred_gmenn_fe = me_model([X_train,Z_train])\n",
    "y_val_pred_gmenn, y_val_pred_gmenn_fe = me_model([X_val,Z_val])\n",
    "y_test_pred_gmenn, y_test_pred_gmenn_fe = me_model([X_test,Z_test])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5673ce4-ee7e-4fe1-8bc0-64b2ed3d2c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7752822132537871"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test.numpy(),y_test_pred_gmenn.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797a1e58-9520-48bc-bf80-4ec2458f1a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcgmenn2",
   "language": "python",
   "name": "mcgmenn2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
