{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a5d56e3-6834-41f6-8ebd-b356b19ddb4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: GPU device not found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "\n",
    "if tf.test.gpu_device_name() != \"/device:GPU:0\":\n",
    "    print(\"WARNING: GPU device not found.\")\n",
    "else:\n",
    "    print(\"SUCCESS: Found GPU: {}\".format(tf.test.gpu_device_name()))\n",
    "\n",
    "import sys\n",
    "\n",
    "# Append root path\n",
    "sys.path.append(\"../\")\n",
    "from data.preprocessing import dataset_preprocessing\n",
    "import pickle\n",
    "\n",
    "from model.mixed_effects import *\n",
    "from utils.utils import *\n",
    "from utils.fe_models import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc0edaa7-892d-49ef-be2d-659ca35a498c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-13 13:21:51.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata.preprocessing.dataset_preprocessing\u001b[0m:\u001b[36mprocess_dataset\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAfter processing the raw dataset churn, intermediate data kept at: ../data/prepared/churn/cv_RS42_hct10_5folds\u001b[0m\n",
      "\u001b[32m2025-02-13 13:21:51.661\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdata.preprocessing.dataset_preprocessing\u001b[0m:\u001b[36mprocess_dataset\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1mColumns in raw dataset: Index(['state', 'account_length', 'area_code', 'international_plan',\n",
      "       'voice_mail_plan', 'number_vmail_messages', 'total_day_minutes',\n",
      "       'total_day_calls', 'total_day_charge', 'total_eve_minutes',\n",
      "       'total_eve_calls', 'total_eve_charge', 'total_night_minutes',\n",
      "       'total_night_calls', 'total_night_charge', 'total_intl_minutes',\n",
      "       'total_intl_calls', 'total_intl_charge',\n",
      "       'number_customer_service_calls', 'class'],\n",
      "      dtype='object')\u001b[0m\n",
      "\u001b[32m2025-02-13 13:21:51.662\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdata.preprocessing.dataset_preprocessing\u001b[0m:\u001b[36mprocess_dataset\u001b[0m:\u001b[36m83\u001b[0m - \u001b[34m\u001b[1mColumns in raw dataset, \u001b[34mafter dropping columns with more than 5% missings values\u001b[0m\u001b[34m\u001b[1m: Index(['state', 'account_length', 'area_code', 'international_plan',\n",
      "       'voice_mail_plan', 'number_vmail_messages', 'total_day_minutes',\n",
      "       'total_day_calls', 'total_day_charge', 'total_eve_minutes',\n",
      "       'total_eve_calls', 'total_eve_charge', 'total_night_minutes',\n",
      "       'total_night_calls', 'total_night_charge', 'total_intl_minutes',\n",
      "       'total_intl_calls', 'total_intl_charge',\n",
      "       'number_customer_service_calls', 'class'],\n",
      "      dtype='object')\u001b[0m\n",
      "\u001b[32m2025-02-13 13:21:51.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata.preprocessing.dataset_preprocessing\u001b[0m:\u001b[36mprocess_dataset\u001b[0m:\u001b[36m666\u001b[0m - \u001b[1mColumn categorization: {'y_col': 'class', 'cat_cols': ['area_code'], 'bin_cols': ['voice_mail_plan', 'international_plan'], 'z_cols': ['number_customer_service_calls', 'state']}.\u001b[0m\n",
      "\u001b[32m2025-02-13 13:21:51.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata.preprocessing.dataset_preprocessing\u001b[0m:\u001b[36mprocess_dataset\u001b[0m:\u001b[36m694\u001b[0m - \u001b[1mShapes: train: (3600, 19); val: (400, 19); test: (1000, 19)\u001b[0m\n",
      "\u001b[32m2025-02-13 13:21:51.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata.preprocessing.dataset_preprocessing\u001b[0m:\u001b[36mprocess_dataset\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1mZ variables: ['number_customer_service_calls', 'state'].\u001b[0m\n",
      "\u001b[32m2025-02-13 13:21:51.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata.preprocessing.dataset_preprocessing\u001b[0m:\u001b[36mprocess_dataset\u001b[0m:\u001b[36m978\u001b[0m - \u001b[1mX variables: Index(['account_length', 'international_plan', 'voice_mail_plan',\n",
      "       'number_vmail_messages', 'total_day_minutes', 'total_day_calls',\n",
      "       'total_day_charge', 'total_eve_minutes', 'total_eve_calls',\n",
      "       'total_eve_charge', 'total_night_minutes', 'total_night_calls',\n",
      "       'total_night_charge', 'total_intl_minutes', 'total_intl_calls',\n",
      "       'total_intl_charge', 'area_code_0', 'area_code_1', 'area_code_2'],\n",
      "      dtype='object').\u001b[0m\n",
      "\u001b[32m2025-02-13 13:21:51.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata.preprocessing.dataset_preprocessing\u001b[0m:\u001b[36mprocess_dataset\u001b[0m:\u001b[36m694\u001b[0m - \u001b[1mShapes: train: (3600, 19); val: (400, 19); test: (1000, 19)\u001b[0m\n",
      "\u001b[32m2025-02-13 13:21:51.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata.preprocessing.dataset_preprocessing\u001b[0m:\u001b[36mprocess_dataset\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1mZ variables: ['number_customer_service_calls', 'state'].\u001b[0m\n",
      "\u001b[32m2025-02-13 13:21:51.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata.preprocessing.dataset_preprocessing\u001b[0m:\u001b[36mprocess_dataset\u001b[0m:\u001b[36m978\u001b[0m - \u001b[1mX variables: Index(['account_length', 'international_plan', 'voice_mail_plan',\n",
      "       'number_vmail_messages', 'total_day_minutes', 'total_day_calls',\n",
      "       'total_day_charge', 'total_eve_minutes', 'total_eve_calls',\n",
      "       'total_eve_charge', 'total_night_minutes', 'total_night_calls',\n",
      "       'total_night_charge', 'total_intl_minutes', 'total_intl_calls',\n",
      "       'total_intl_charge', 'area_code_0', 'area_code_1', 'area_code_2'],\n",
      "      dtype='object').\u001b[0m\n",
      "\u001b[32m2025-02-13 13:21:51.749\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata.preprocessing.dataset_preprocessing\u001b[0m:\u001b[36mprocess_dataset\u001b[0m:\u001b[36m694\u001b[0m - \u001b[1mShapes: train: (3600, 19); val: (400, 19); test: (1000, 19)\u001b[0m\n",
      "\u001b[32m2025-02-13 13:21:51.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata.preprocessing.dataset_preprocessing\u001b[0m:\u001b[36mprocess_dataset\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1mZ variables: ['number_customer_service_calls', 'state'].\u001b[0m\n",
      "\u001b[32m2025-02-13 13:21:51.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata.preprocessing.dataset_preprocessing\u001b[0m:\u001b[36mprocess_dataset\u001b[0m:\u001b[36m978\u001b[0m - \u001b[1mX variables: Index(['account_length', 'international_plan', 'voice_mail_plan',\n",
      "       'number_vmail_messages', 'total_day_minutes', 'total_day_calls',\n",
      "       'total_day_charge', 'total_eve_minutes', 'total_eve_calls',\n",
      "       'total_eve_charge', 'total_night_minutes', 'total_night_calls',\n",
      "       'total_night_charge', 'total_intl_minutes', 'total_intl_calls',\n",
      "       'total_intl_charge', 'area_code_0', 'area_code_1', 'area_code_2'],\n",
      "      dtype='object').\u001b[0m\n",
      "\u001b[32m2025-02-13 13:21:51.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata.preprocessing.dataset_preprocessing\u001b[0m:\u001b[36mprocess_dataset\u001b[0m:\u001b[36m694\u001b[0m - \u001b[1mShapes: train: (3600, 19); val: (400, 19); test: (1000, 19)\u001b[0m\n",
      "\u001b[32m2025-02-13 13:21:51.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata.preprocessing.dataset_preprocessing\u001b[0m:\u001b[36mprocess_dataset\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1mZ variables: ['number_customer_service_calls', 'state'].\u001b[0m\n",
      "\u001b[32m2025-02-13 13:21:51.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata.preprocessing.dataset_preprocessing\u001b[0m:\u001b[36mprocess_dataset\u001b[0m:\u001b[36m978\u001b[0m - \u001b[1mX variables: Index(['account_length', 'international_plan', 'voice_mail_plan',\n",
      "       'number_vmail_messages', 'total_day_minutes', 'total_day_calls',\n",
      "       'total_day_charge', 'total_eve_minutes', 'total_eve_calls',\n",
      "       'total_eve_charge', 'total_night_minutes', 'total_night_calls',\n",
      "       'total_night_charge', 'total_intl_minutes', 'total_intl_calls',\n",
      "       'total_intl_charge', 'area_code_0', 'area_code_1', 'area_code_2'],\n",
      "      dtype='object').\u001b[0m\n",
      "\u001b[32m2025-02-13 13:21:51.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata.preprocessing.dataset_preprocessing\u001b[0m:\u001b[36mprocess_dataset\u001b[0m:\u001b[36m694\u001b[0m - \u001b[1mShapes: train: (3600, 19); val: (400, 19); test: (1000, 19)\u001b[0m\n",
      "\u001b[32m2025-02-13 13:21:51.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata.preprocessing.dataset_preprocessing\u001b[0m:\u001b[36mprocess_dataset\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1mZ variables: ['number_customer_service_calls', 'state'].\u001b[0m\n",
      "\u001b[32m2025-02-13 13:21:51.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata.preprocessing.dataset_preprocessing\u001b[0m:\u001b[36mprocess_dataset\u001b[0m:\u001b[36m978\u001b[0m - \u001b[1mX variables: Index(['account_length', 'international_plan', 'voice_mail_plan',\n",
      "       'number_vmail_messages', 'total_day_minutes', 'total_day_calls',\n",
      "       'total_day_charge', 'total_eve_minutes', 'total_eve_calls',\n",
      "       'total_eve_charge', 'total_night_minutes', 'total_night_calls',\n",
      "       'total_night_charge', 'total_intl_minutes', 'total_intl_calls',\n",
      "       'total_intl_charge', 'area_code_0', 'area_code_1', 'area_code_2'],\n",
      "      dtype='object').\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Append root path\n",
    "sys.path.append(\"../\")\n",
    "from data.preprocessing import dataset_preprocessing\n",
    "import pickle\n",
    "\n",
    "dataset_name = \"churn\"\n",
    "target = \"binary\"\n",
    "mode = \"cv\"\n",
    "RS = 42\n",
    "hct = 10\n",
    "test_ratio = 0.1\n",
    "val_ratio = 0.1\n",
    "folds = 5\n",
    "\n",
    "# Attention: preprocessing script is meant to be executed from the notebooks directory\n",
    "dataset_preprocessing.process_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    target=target,\n",
    "    mode=mode,\n",
    "    RS=RS,\n",
    "    hct=hct,\n",
    "    test_ratio=test_ratio,\n",
    "    val_ratio=val_ratio,\n",
    "    folds=folds,\n",
    ")\n",
    "data_path = f\"{mode}_RS{RS}_hct{hct}_{folds}folds\"\n",
    "\n",
    "with open(\n",
    "    f\"../data/prepared/{dataset_name}/{data_path}/data_dict.pickle\", \"rb\"\n",
    ") as handle:\n",
    "    data_dict = pickle.load(handle)\n",
    "\n",
    "fold_num = 0\n",
    "x_cols = data_dict[f\"X_train_{fold_num}\"].columns\n",
    "X_train = data_dict[f\"X_train_{fold_num}\"]\n",
    "Z_train = data_dict[f\"Z_train_{fold_num}\"]\n",
    "y_train = data_dict[f\"y_train_{fold_num}\"]\n",
    "\n",
    "X_val = data_dict[f\"X_val_{fold_num}\"]\n",
    "Z_val = data_dict[f\"Z_val_{fold_num}\"]\n",
    "y_val = data_dict[f\"y_val_{fold_num}\"]\n",
    "\n",
    "X_test = data_dict[f\"X_test_{fold_num}\"]\n",
    "Z_test = data_dict[f\"Z_test_{fold_num}\"]\n",
    "y_test = data_dict[f\"y_test_{fold_num}\"]\n",
    "\n",
    "qs = (\n",
    "    np.max(\n",
    "        [\n",
    "            tf.reduce_max(Z_train, axis=0),\n",
    "            tf.reduce_max(Z_val, axis=0),\n",
    "            tf.reduce_max(Z_test, axis=0),\n",
    "        ],\n",
    "        axis=0,\n",
    "    )\n",
    "    + 1\n",
    ")\n",
    "\n",
    "X_train = tf.convert_to_tensor(X_train)\n",
    "Z_train = tf.convert_to_tensor(Z_train, dtype=tf.int32)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "\n",
    "X_val = tf.convert_to_tensor(X_val)\n",
    "Z_val = tf.convert_to_tensor(Z_val, dtype=tf.int32)\n",
    "y_val = tf.convert_to_tensor(y_val)\n",
    "\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "Z_test = tf.convert_to_tensor(Z_test, dtype=tf.int32)\n",
    "y_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd9f350-3f29-4b22-9dba-8d8a39fb059a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n",
      "\n",
      " Start sampling for epoch 1 of training\n",
      "Epoch 1/500\n",
      "8/8 [==============================] - 1s 16ms/step - me_loss: 0.7702 - me_loss_val: 0.7543 - fe_loss: 0.5995 - fe_loss_val: 0.5971 - me_auc: 0.4605 - me_auc_val: 0.4520 - fe_auc: 0.5526 - fe_auc_val: 0.5377 - stds: 0.8128 - acceptance_rate: 0.0000e+00\n",
      "Adapt step size to 0.05000000074505806\n",
      "\n",
      " Start sampling for epoch 2 of training\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 0s 7ms/step - me_loss: 0.7092 - me_loss_val: 0.6947 - fe_loss: 0.5438 - fe_loss_val: 0.5427 - me_auc: 0.4719 - me_auc_val: 0.4648 - fe_auc: 0.6040 - fe_auc_val: 0.5946 - stds: 0.8128 - acceptance_rate: 0.0000e+00\n",
      "Adapt step size to 0.02500000037252903\n",
      "\n",
      " Start sampling for epoch 3 of training\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 0s 8ms/step - me_loss: 0.6677 - me_loss_val: 0.6538 - fe_loss: 0.5078 - fe_loss_val: 0.5071 - me_auc: 0.4731 - me_auc_val: 0.4657 - fe_auc: 0.6179 - fe_auc_val: 0.5968 - stds: 0.8128 - acceptance_rate: 0.0000e+00\n",
      "Adapt step size to 0.012500000186264515\n",
      "\n",
      " Start sampling for epoch 4 of training\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 0s 8ms/step - me_loss: 0.6343 - me_loss_val: 0.6199 - fe_loss: 0.4803 - fe_loss_val: 0.4795 - me_auc: 0.4726 - me_auc_val: 0.4651 - fe_auc: 0.6175 - fe_auc_val: 0.5864 - stds: 0.8128 - acceptance_rate: 0.0000e+00\n",
      "Adapt step size to 0.0062500000931322575\n",
      "\n",
      " Start sampling for epoch 5 of training\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 0s 8ms/step - me_loss: 0.6053 - me_loss_val: 0.5895 - fe_loss: 0.4575 - fe_loss_val: 0.4557 - me_auc: 0.4750 - me_auc_val: 0.4703 - fe_auc: 0.6205 - fe_auc_val: 0.5957 - stds: 0.8128 - acceptance_rate: 0.0000e+00\n",
      "Adapt step size to 0.0031250000465661287\n",
      "\n",
      " Start sampling for epoch 6 of training\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 0s 8ms/step - me_loss: 0.5822 - me_loss_val: 0.5650 - fe_loss: 0.4404 - fe_loss_val: 0.4372 - me_auc: 0.4767 - me_auc_val: 0.4739 - fe_auc: 0.6229 - fe_auc_val: 0.6089 - stds: 0.8128 - acceptance_rate: 0.0000e+00\n",
      "Adapt step size to 0.0015625000232830644\n",
      "\n",
      " Start sampling for epoch 7 of training\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 0s 8ms/step - me_loss: 0.5128 - me_loss_val: 0.4949 - fe_loss: 0.4278 - fe_loss_val: 0.4241 - me_auc: 0.4928 - me_auc_val: 0.4958 - fe_auc: 0.6338 - fe_auc_val: 0.6208 - stds: 0.6629 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 8 of training\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 0s 8ms/step - me_loss: 0.4636 - me_loss_val: 0.4466 - fe_loss: 0.4165 - fe_loss_val: 0.4124 - me_auc: 0.5124 - me_auc_val: 0.5196 - fe_auc: 0.6430 - fe_auc_val: 0.6324 - stds: 0.5678 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 9 of training\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 0s 8ms/step - me_loss: 0.4267 - me_loss_val: 0.4120 - fe_loss: 0.4088 - fe_loss_val: 0.4041 - me_auc: 0.5404 - me_auc_val: 0.5531 - fe_auc: 0.6451 - fe_auc_val: 0.6352 - stds: 0.2949 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 10 of training\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 0s 8ms/step - me_loss: 0.4165 - me_loss_val: 0.4031 - fe_loss: 0.4028 - fe_loss_val: 0.3975 - me_auc: 0.5570 - me_auc_val: 0.5707 - fe_auc: 0.6527 - fe_auc_val: 0.6451 - stds: 0.2172 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 11 of training\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 0s 8ms/step - me_loss: 0.4048 - me_loss_val: 0.3941 - fe_loss: 0.3987 - fe_loss_val: 0.3940 - me_auc: 0.6049 - me_auc_val: 0.6191 - fe_auc: 0.6610 - fe_auc_val: 0.6495 - stds: 0.2257 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 12 of training\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 0s 8ms/step - me_loss: 0.3975 - me_loss_val: 0.3895 - fe_loss: 0.3942 - fe_loss_val: 0.3897 - me_auc: 0.6463 - me_auc_val: 0.6502 - fe_auc: 0.6753 - fe_auc_val: 0.6617 - stds: 0.2186 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 13 of training\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 0s 8ms/step - me_loss: 0.3963 - me_loss_val: 0.3890 - fe_loss: 0.3911 - fe_loss_val: 0.3868 - me_auc: 0.6588 - me_auc_val: 0.6563 - fe_auc: 0.6847 - fe_auc_val: 0.6702 - stds: 0.2232 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 14 of training\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3913 - me_loss_val: 0.3850 - fe_loss: 0.3868 - fe_loss_val: 0.3819 - me_auc: 0.6865 - me_auc_val: 0.6720 - fe_auc: 0.7009 - fe_auc_val: 0.6865 - stds: 0.2341 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 15 of training\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3892 - me_loss_val: 0.3830 - fe_loss: 0.3838 - fe_loss_val: 0.3783 - me_auc: 0.6941 - me_auc_val: 0.6748 - fe_auc: 0.7124 - fe_auc_val: 0.6994 - stds: 0.0921 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 16 of training\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3895 - me_loss_val: 0.3843 - fe_loss: 0.3829 - fe_loss_val: 0.3783 - me_auc: 0.6999 - me_auc_val: 0.6717 - fe_auc: 0.7187 - fe_auc_val: 0.6992 - stds: 0.0844 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 17 of training\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3876 - me_loss_val: 0.3837 - fe_loss: 0.3817 - fe_loss_val: 0.3779 - me_auc: 0.7071 - me_auc_val: 0.6736 - fe_auc: 0.7262 - fe_auc_val: 0.6986 - stds: 0.0707 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 18 of training\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 0s 8ms/step - me_loss: 0.3840 - me_loss_val: 0.3811 - fe_loss: 0.3792 - fe_loss_val: 0.3760 - me_auc: 0.7197 - me_auc_val: 0.6790 - fe_auc: 0.7366 - fe_auc_val: 0.7078 - stds: 0.0652 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 19 of training\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 0s 8ms/step - me_loss: 0.3812 - me_loss_val: 0.3799 - fe_loss: 0.3771 - fe_loss_val: 0.3752 - me_auc: 0.7290 - me_auc_val: 0.6838 - fe_auc: 0.7459 - fe_auc_val: 0.7104 - stds: 0.0606 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 20 of training\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3789 - me_loss_val: 0.3783 - fe_loss: 0.3752 - fe_loss_val: 0.3737 - me_auc: 0.7400 - me_auc_val: 0.6860 - fe_auc: 0.7575 - fe_auc_val: 0.7155 - stds: 0.0611 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 21 of training\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 0s 8ms/step - me_loss: 0.3768 - me_loss_val: 0.3760 - fe_loss: 0.3743 - fe_loss_val: 0.3724 - me_auc: 0.7465 - me_auc_val: 0.6891 - fe_auc: 0.7637 - fe_auc_val: 0.7196 - stds: 0.0620 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 22 of training\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 0s 8ms/step - me_loss: 0.3739 - me_loss_val: 0.3735 - fe_loss: 0.3728 - fe_loss_val: 0.3710 - me_auc: 0.7544 - me_auc_val: 0.6955 - fe_auc: 0.7694 - fe_auc_val: 0.7243 - stds: 0.0634 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 23 of training\n",
      "Epoch 23/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3716 - me_loss_val: 0.3715 - fe_loss: 0.3711 - fe_loss_val: 0.3695 - me_auc: 0.7588 - me_auc_val: 0.7055 - fe_auc: 0.7742 - fe_auc_val: 0.7319 - stds: 0.0696 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 24 of training\n",
      "Epoch 24/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3669 - me_loss_val: 0.3672 - fe_loss: 0.3674 - fe_loss_val: 0.3660 - me_auc: 0.7638 - me_auc_val: 0.7112 - fe_auc: 0.7791 - fe_auc_val: 0.7348 - stds: 0.0719 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 25 of training\n",
      "Epoch 25/500\n",
      "8/8 [==============================] - 0s 8ms/step - me_loss: 0.3652 - me_loss_val: 0.3672 - fe_loss: 0.3664 - fe_loss_val: 0.3665 - me_auc: 0.7765 - me_auc_val: 0.7128 - fe_auc: 0.7905 - fe_auc_val: 0.7380 - stds: 0.0748 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 26 of training\n",
      "Epoch 26/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3635 - me_loss_val: 0.3659 - fe_loss: 0.3650 - fe_loss_val: 0.3656 - me_auc: 0.7846 - me_auc_val: 0.7113 - fe_auc: 0.8016 - fe_auc_val: 0.7354 - stds: 0.0696 - acceptance_rate: 0.6810\n",
      "\n",
      " Start sampling for epoch 27 of training\n",
      "Epoch 27/500\n",
      "8/8 [==============================] - 0s 10ms/step - me_loss: 0.3600 - me_loss_val: 0.3638 - fe_loss: 0.3623 - fe_loss_val: 0.3641 - me_auc: 0.7976 - me_auc_val: 0.7153 - fe_auc: 0.8138 - fe_auc_val: 0.7409 - stds: 0.0737 - acceptance_rate: 0.9579\n",
      "\n",
      " Start sampling for epoch 28 of training\n",
      "Epoch 28/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3575 - me_loss_val: 0.3634 - fe_loss: 0.3606 - fe_loss_val: 0.3644 - me_auc: 0.8107 - me_auc_val: 0.7163 - fe_auc: 0.8266 - fe_auc_val: 0.7423 - stds: 0.0786 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 29 of training\n",
      "Epoch 29/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3546 - me_loss_val: 0.3604 - fe_loss: 0.3586 - fe_loss_val: 0.3626 - me_auc: 0.8067 - me_auc_val: 0.7182 - fe_auc: 0.8245 - fe_auc_val: 0.7447 - stds: 0.0836 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 30 of training\n",
      "Epoch 30/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3521 - me_loss_val: 0.3570 - fe_loss: 0.3568 - fe_loss_val: 0.3598 - me_auc: 0.8101 - me_auc_val: 0.7243 - fe_auc: 0.8274 - fe_auc_val: 0.7536 - stds: 0.0898 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 31 of training\n",
      "Epoch 31/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3494 - me_loss_val: 0.3557 - fe_loss: 0.3548 - fe_loss_val: 0.3587 - me_auc: 0.8131 - me_auc_val: 0.7258 - fe_auc: 0.8305 - fe_auc_val: 0.7534 - stds: 0.0960 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 32 of training\n",
      "Epoch 32/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3488 - me_loss_val: 0.3574 - fe_loss: 0.3547 - fe_loss_val: 0.3610 - me_auc: 0.8210 - me_auc_val: 0.7227 - fe_auc: 0.8389 - fe_auc_val: 0.7508 - stds: 0.0997 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 33 of training\n",
      "Epoch 33/500\n",
      "8/8 [==============================] - 0s 10ms/step - me_loss: 0.3444 - me_loss_val: 0.3542 - fe_loss: 0.3510 - fe_loss_val: 0.3585 - me_auc: 0.8295 - me_auc_val: 0.7302 - fe_auc: 0.8483 - fe_auc_val: 0.7550 - stds: 0.0992 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 34 of training\n",
      "Epoch 34/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3377 - me_loss_val: 0.3487 - fe_loss: 0.3444 - fe_loss_val: 0.3532 - me_auc: 0.8307 - me_auc_val: 0.7338 - fe_auc: 0.8500 - fe_auc_val: 0.7581 - stds: 0.1034 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 35 of training\n",
      "Epoch 35/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3369 - me_loss_val: 0.3503 - fe_loss: 0.3438 - fe_loss_val: 0.3550 - me_auc: 0.8464 - me_auc_val: 0.7344 - fe_auc: 0.8667 - fe_auc_val: 0.7636 - stds: 0.1131 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 36 of training\n",
      "Epoch 36/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3346 - me_loss_val: 0.3486 - fe_loss: 0.3412 - fe_loss_val: 0.3530 - me_auc: 0.8506 - me_auc_val: 0.7380 - fe_auc: 0.8689 - fe_auc_val: 0.7674 - stds: 0.1135 - acceptance_rate: 0.9213\n",
      "\n",
      " Start sampling for epoch 37 of training\n",
      "Epoch 37/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3323 - me_loss_val: 0.3461 - fe_loss: 0.3380 - fe_loss_val: 0.3498 - me_auc: 0.8457 - me_auc_val: 0.7426 - fe_auc: 0.8646 - fe_auc_val: 0.7688 - stds: 0.1216 - acceptance_rate: 0.8951\n",
      "\n",
      " Start sampling for epoch 38 of training\n",
      "Epoch 38/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3272 - me_loss_val: 0.3423 - fe_loss: 0.3327 - fe_loss_val: 0.3454 - me_auc: 0.8544 - me_auc_val: 0.7479 - fe_auc: 0.8748 - fe_auc_val: 0.7752 - stds: 0.1208 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 39 of training\n",
      "Epoch 39/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3250 - me_loss_val: 0.3430 - fe_loss: 0.3304 - fe_loss_val: 0.3457 - me_auc: 0.8677 - me_auc_val: 0.7384 - fe_auc: 0.8885 - fe_auc_val: 0.7708 - stds: 0.1214 - acceptance_rate: 0.8536\n",
      "\n",
      " Start sampling for epoch 40 of training\n",
      "Epoch 40/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3184 - me_loss_val: 0.3386 - fe_loss: 0.3233 - fe_loss_val: 0.3409 - me_auc: 0.8617 - me_auc_val: 0.7341 - fe_auc: 0.8837 - fe_auc_val: 0.7618 - stds: 0.1225 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 41 of training\n",
      "Epoch 41/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3145 - me_loss_val: 0.3365 - fe_loss: 0.3187 - fe_loss_val: 0.3380 - me_auc: 0.8647 - me_auc_val: 0.7408 - fe_auc: 0.8872 - fe_auc_val: 0.7691 - stds: 0.1316 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 42 of training\n",
      "Epoch 42/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3126 - me_loss_val: 0.3370 - fe_loss: 0.3172 - fe_loss_val: 0.3386 - me_auc: 0.8784 - me_auc_val: 0.7419 - fe_auc: 0.9009 - fe_auc_val: 0.7742 - stds: 0.1408 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 43 of training\n",
      "Epoch 43/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3136 - me_loss_val: 0.3392 - fe_loss: 0.3190 - fe_loss_val: 0.3414 - me_auc: 0.8845 - me_auc_val: 0.7409 - fe_auc: 0.9051 - fe_auc_val: 0.7758 - stds: 0.1427 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 44 of training\n",
      "Epoch 44/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.3055 - me_loss_val: 0.3304 - fe_loss: 0.3091 - fe_loss_val: 0.3310 - me_auc: 0.8841 - me_auc_val: 0.7524 - fe_auc: 0.9058 - fe_auc_val: 0.7814 - stds: 0.1468 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 45 of training\n",
      "Epoch 45/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.2967 - me_loss_val: 0.3196 - fe_loss: 0.2980 - fe_loss_val: 0.3180 - me_auc: 0.8753 - me_auc_val: 0.7569 - fe_auc: 0.8973 - fe_auc_val: 0.7848 - stds: 0.1438 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 46 of training\n",
      "Epoch 46/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.2973 - me_loss_val: 0.3236 - fe_loss: 0.2987 - fe_loss_val: 0.3219 - me_auc: 0.8931 - me_auc_val: 0.7642 - fe_auc: 0.9143 - fe_auc_val: 0.7920 - stds: 0.1406 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 47 of training\n",
      "Epoch 47/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.2977 - me_loss_val: 0.3279 - fe_loss: 0.2990 - fe_loss_val: 0.3260 - me_auc: 0.9004 - me_auc_val: 0.7562 - fe_auc: 0.9232 - fe_auc_val: 0.7867 - stds: 0.1571 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 48 of training\n",
      "Epoch 48/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.2956 - me_loss_val: 0.3274 - fe_loss: 0.2976 - fe_loss_val: 0.3266 - me_auc: 0.8892 - me_auc_val: 0.7432 - fe_auc: 0.9144 - fe_auc_val: 0.7818 - stds: 0.1598 - acceptance_rate: 0.9475\n",
      "\n",
      " Start sampling for epoch 49 of training\n",
      "Epoch 49/500\n",
      "8/8 [==============================] - 0s 8ms/step - me_loss: 0.2929 - me_loss_val: 0.3276 - fe_loss: 0.2954 - fe_loss_val: 0.3277 - me_auc: 0.8914 - me_auc_val: 0.7426 - fe_auc: 0.9173 - fe_auc_val: 0.7797 - stds: 0.1638 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 50 of training\n",
      "Epoch 50/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.2886 - me_loss_val: 0.3264 - fe_loss: 0.2910 - fe_loss_val: 0.3263 - me_auc: 0.8992 - me_auc_val: 0.7433 - fe_auc: 0.9239 - fe_auc_val: 0.7765 - stds: 0.1697 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 51 of training\n",
      "Epoch 51/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.2848 - me_loss_val: 0.3235 - fe_loss: 0.2867 - fe_loss_val: 0.3225 - me_auc: 0.9029 - me_auc_val: 0.7418 - fe_auc: 0.9281 - fe_auc_val: 0.7793 - stds: 0.1771 - acceptance_rate: 0.8426\n",
      "\n",
      " Start sampling for epoch 52 of training\n",
      "Epoch 52/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.2822 - me_loss_val: 0.3208 - fe_loss: 0.2831 - fe_loss_val: 0.3187 - me_auc: 0.9103 - me_auc_val: 0.7532 - fe_auc: 0.9345 - fe_auc_val: 0.7899 - stds: 0.1848 - acceptance_rate: 0.6126\n",
      "\n",
      " Start sampling for epoch 53 of training\n",
      "Epoch 53/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.2773 - me_loss_val: 0.3154 - fe_loss: 0.2774 - fe_loss_val: 0.3124 - me_auc: 0.9079 - me_auc_val: 0.7536 - fe_auc: 0.9329 - fe_auc_val: 0.7893 - stds: 0.1891 - acceptance_rate: 0.8377\n",
      "\n",
      " Start sampling for epoch 54 of training\n",
      "Epoch 54/500\n",
      "8/8 [==============================] - 0s 8ms/step - me_loss: 0.2744 - me_loss_val: 0.3161 - fe_loss: 0.2743 - fe_loss_val: 0.3126 - me_auc: 0.9190 - me_auc_val: 0.7526 - fe_auc: 0.9445 - fe_auc_val: 0.7924 - stds: 0.2049 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 55 of training\n",
      "Epoch 55/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.2725 - me_loss_val: 0.3188 - fe_loss: 0.2731 - fe_loss_val: 0.3158 - me_auc: 0.9261 - me_auc_val: 0.7445 - fe_auc: 0.9513 - fe_auc_val: 0.7847 - stds: 0.2076 - acceptance_rate: 0.8529\n",
      "\n",
      " Start sampling for epoch 56 of training\n",
      "Epoch 56/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.2698 - me_loss_val: 0.3173 - fe_loss: 0.2688 - fe_loss_val: 0.3130 - me_auc: 0.9234 - me_auc_val: 0.7387 - fe_auc: 0.9496 - fe_auc_val: 0.7788 - stds: 0.2126 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 57 of training\n",
      "Epoch 57/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.2674 - me_loss_val: 0.3141 - fe_loss: 0.2645 - fe_loss_val: 0.3078 - me_auc: 0.9165 - me_auc_val: 0.7421 - fe_auc: 0.9436 - fe_auc_val: 0.7783 - stds: 0.2067 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 58 of training\n",
      "Epoch 58/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.2666 - me_loss_val: 0.3145 - fe_loss: 0.2637 - fe_loss_val: 0.3085 - me_auc: 0.9177 - me_auc_val: 0.7397 - fe_auc: 0.9462 - fe_auc_val: 0.7793 - stds: 0.2096 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 59 of training\n",
      "Epoch 59/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.2661 - me_loss_val: 0.3174 - fe_loss: 0.2629 - fe_loss_val: 0.3110 - me_auc: 0.9282 - me_auc_val: 0.7397 - fe_auc: 0.9549 - fe_auc_val: 0.7785 - stds: 0.2257 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 60 of training\n",
      "Epoch 60/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.2624 - me_loss_val: 0.3182 - fe_loss: 0.2578 - fe_loss_val: 0.3108 - me_auc: 0.9339 - me_auc_val: 0.7386 - fe_auc: 0.9595 - fe_auc_val: 0.7798 - stds: 0.2313 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 61 of training\n",
      "Epoch 61/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.2595 - me_loss_val: 0.3179 - fe_loss: 0.2551 - fe_loss_val: 0.3107 - me_auc: 0.9417 - me_auc_val: 0.7407 - fe_auc: 0.9667 - fe_auc_val: 0.7840 - stds: 0.2344 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 62 of training\n",
      "Epoch 62/500\n",
      "8/8 [==============================] - 0s 11ms/step - me_loss: 0.2546 - me_loss_val: 0.3157 - fe_loss: 0.2500 - fe_loss_val: 0.3079 - me_auc: 0.9437 - me_auc_val: 0.7394 - fe_auc: 0.9683 - fe_auc_val: 0.7849 - stds: 0.2421 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 63 of training\n",
      "Epoch 63/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.2512 - me_loss_val: 0.3145 - fe_loss: 0.2467 - fe_loss_val: 0.3063 - me_auc: 0.9469 - me_auc_val: 0.7421 - fe_auc: 0.9704 - fe_auc_val: 0.7876 - stds: 0.2516 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 64 of training\n",
      "Epoch 64/500\n",
      "8/8 [==============================] - 0s 8ms/step - me_loss: 0.2495 - me_loss_val: 0.3131 - fe_loss: 0.2441 - fe_loss_val: 0.3030 - me_auc: 0.9429 - me_auc_val: 0.7394 - fe_auc: 0.9676 - fe_auc_val: 0.7854 - stds: 0.2720 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 65 of training\n",
      "Epoch 65/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.2455 - me_loss_val: 0.3115 - fe_loss: 0.2390 - fe_loss_val: 0.3005 - me_auc: 0.9411 - me_auc_val: 0.7414 - fe_auc: 0.9661 - fe_auc_val: 0.7894 - stds: 0.2802 - acceptance_rate: 1.0000\n",
      "\n",
      " Start sampling for epoch 66 of training\n",
      "Epoch 66/500\n",
      "8/8 [==============================] - 0s 9ms/step - me_loss: 0.2447 - me_loss_val: 0.3139 - fe_loss: 0.2358 - fe_loss_val: 0.3011 - me_auc: 0.9381 - me_auc_val: 0.7362 - fe_auc: 0.9645 - fe_auc_val: 0.7823 - stds: 0.2836 - acceptance_rate: 1.0000\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(RS)\n",
    "np.random.seed(RS)\n",
    "\n",
    "batch_size = 512\n",
    "epochs = 500\n",
    "early_stopping = 20\n",
    "model_name = \"AutoGluon\"\n",
    "loss_use = lambda: tf.keras.losses.BinaryCrossentropy\n",
    "\n",
    "\n",
    "if target == \"categorical\":\n",
    "    n_classes = np.unique(y_train).shape[0]\n",
    "elif target == \"binary\":\n",
    "    n_classes = 1\n",
    "\n",
    "d = X_train.shape[1]  # columns\n",
    "n = X_train.shape[0]  # rows\n",
    "num_outputs = n_classes\n",
    "perc_numeric = d / (d + Z_train.shape[1])\n",
    "\n",
    "#             qs = np.max([tf.reduce_max(Z_train, axis=0),tf.reduce_max(Z_val, axis=0),tf.reduce_max(Z_test, axis=0)],axis=0)+1\n",
    "\n",
    "set_seed(RS)\n",
    "\n",
    "fe_model, optimizer = get_model(\n",
    "    model_name=model_name,\n",
    "    input_size=X_train.shape[1],\n",
    "    output_size=num_outputs,\n",
    "    target=target,\n",
    "    perc_numeric=perc_numeric,\n",
    "    RS=RS,\n",
    ")\n",
    "\n",
    "initial_stds = np.ones([len(qs), num_outputs]).astype(float).tolist()\n",
    "\n",
    "me_model = MixedEffectsNetwork(\n",
    "    X_train,\n",
    "    Z_train,\n",
    "    y_train,\n",
    "    fe_model,\n",
    "    target=target,\n",
    "    qs=qs,\n",
    "    initial_stds=initial_stds,\n",
    "    fe_loss_weight=1.0,\n",
    "    mode=\"intercepts\",\n",
    "    early_stopping_fe=early_stopping,\n",
    ")\n",
    "\n",
    "me_model.compile(\n",
    "    loss_class_me=loss_use()(),\n",
    "    loss_class_fe=loss_use()(),\n",
    "    #     metric_class_me = tf.keras.metrics.AUC(multi_label=True, name=\"auc_me\"),\n",
    "    #     metric_class_fe = tf.keras.metrics.AUC(multi_label=True, name=\"auc_fe\"),\n",
    "    optimizer=optimizer,\n",
    ")\n",
    "\n",
    "mcmc = MCMCSamplingCallback(\n",
    "    num_mcmc_samples=1,\n",
    "    perc_burnin=0.7,\n",
    "    warm_restart=None,\n",
    "    num_burnin_steps=1,\n",
    "    step_size=0.1,  # initial_step_size,\n",
    ")\n",
    "\n",
    "\n",
    "print_metric = PrintMetrics(X_train, Z_train, y_train, X_val, Z_val, y_val)\n",
    "\n",
    "start = time.time()\n",
    "history = me_model.fit(\n",
    "    [X_train, Z_train],\n",
    "    y_train,\n",
    "    callbacks=[\n",
    "        mcmc,\n",
    "        print_metric,\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"me_auc_val\", patience=early_stopping, mode=\"max\"\n",
    "        ),\n",
    "    ],\n",
    "    epochs=epochs,\n",
    "    validation_data=[[X_val, Z_val], y_val],\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "fit_time_gmenn = round(end - start, 2)\n",
    "\n",
    "y_train_pred_gmenn, y_train_pred_gmenn_fe = me_model([X_train, Z_train])\n",
    "y_val_pred_gmenn, y_val_pred_gmenn_fe = me_model([X_val, Z_val])\n",
    "y_test_pred_gmenn, y_test_pred_gmenn_fe = me_model([X_test, Z_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5673ce4-ee7e-4fe1-8bc0-64b2ed3d2c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7747307380576376"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test.numpy(), y_test_pred_gmenn.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797a1e58-9520-48bc-bf80-4ec2458f1a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcgmenn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
