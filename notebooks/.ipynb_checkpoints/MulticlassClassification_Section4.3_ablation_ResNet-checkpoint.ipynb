{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eb4febc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: Found GPU: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Append root path \n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../lmmnn\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
    "    print('WARNING: GPU device not found.')\n",
    "else:\n",
    "    print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "from model.mixed_effects import *\n",
    "from utils.fe_models import get_model\n",
    "from utils.evaluation import *\n",
    "from utils.utils import *\n",
    "from data.preprocessing import dataset_preprocessing\n",
    "\n",
    "# from vis.utils.utils import apply_modifications\n",
    "# helper function\n",
    "def update_layer_activation(model, activation, index=-1):\n",
    "    model.layers[index].activation = activation\n",
    "    return model\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Reshape, Embedding, Concatenate\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import roc_auc_score as auroc\n",
    "from sklearn.metrics import f1_score as f1\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import TargetEncoder\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import yaml\n",
    "import time\n",
    "import gc\n",
    "\n",
    "RS = 555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2591484f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8f4d14a",
   "metadata": {},
   "source": [
    "#### Download and save data from Pargent et al. by running \"data/download_pargent2022_datasets.py before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65a5c35f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training procedure for eucalyptus\n",
      "Fold no. 0\n",
      "Load results for dataset eucalyptus, iteration=0\n",
      "Fold no. 1\n",
      "Load results for dataset eucalyptus, iteration=1\n",
      "Fold no. 2\n",
      "Load results for dataset eucalyptus, iteration=2\n",
      "Fold no. 3\n",
      "Load results for dataset eucalyptus, iteration=3\n",
      "Fold no. 4\n",
      "Load results for dataset eucalyptus, iteration=4\n",
      "Start training procedure for Midwest_survey\n",
      "Fold no. 0\n",
      "Load results for dataset Midwest_survey, iteration=0\n",
      "Fold no. 1\n",
      "Load results for dataset Midwest_survey, iteration=1\n",
      "Fold no. 2\n",
      "Load results for dataset Midwest_survey, iteration=2\n",
      "Fold no. 3\n",
      "Load results for dataset Midwest_survey, iteration=3\n",
      "Fold no. 4\n",
      "Load results for dataset Midwest_survey, iteration=4\n",
      "Start training procedure for hpc-job-scheduling\n",
      "Fold no. 0\n",
      "Load results for dataset hpc-job-scheduling, iteration=0\n",
      "Fold no. 1\n",
      "Load results for dataset hpc-job-scheduling, iteration=1\n",
      "Fold no. 2\n",
      "Load results for dataset hpc-job-scheduling, iteration=2\n",
      "Fold no. 3\n",
      "Load results for dataset hpc-job-scheduling, iteration=3\n",
      "Fold no. 4\n",
      "Load results for dataset hpc-job-scheduling, iteration=4\n",
      "Start training procedure for video-game-sales\n",
      "Fold no. 0\n",
      "Load results for dataset video-game-sales, iteration=0\n",
      "Fold no. 1\n",
      "Load results for dataset video-game-sales, iteration=1\n",
      "Fold no. 2\n",
      "Load results for dataset video-game-sales, iteration=2\n",
      "Fold no. 3\n",
      "Load results for dataset video-game-sales, iteration=3\n",
      "Fold no. 4\n",
      "Load results for dataset video-game-sales, iteration=4\n",
      "Start training procedure for okcupid-stem\n",
      "Fold no. 0\n",
      "Load results for dataset okcupid-stem, iteration=0\n",
      "Fold no. 1\n",
      "Load results for dataset okcupid-stem, iteration=1\n",
      "Fold no. 2\n",
      "Load results for dataset okcupid-stem, iteration=2\n",
      "Fold no. 3\n",
      "Load results for dataset okcupid-stem, iteration=3\n",
      "Fold no. 4\n",
      "Load results for dataset okcupid-stem, iteration=4\n",
      "Start training procedure for Diabetes130US\n",
      "Fold no. 0\n",
      "Load results for dataset Diabetes130US, iteration=0\n",
      "Fold no. 1\n",
      "Load results for dataset Diabetes130US, iteration=1\n",
      "Fold no. 2\n",
      "Load results for dataset Diabetes130US, iteration=2\n",
      "Fold no. 3\n",
      "Load results for dataset Diabetes130US, iteration=3\n",
      "Fold no. 4\n",
      "Load results for dataset Diabetes130US, iteration=4\n"
     ]
    }
   ],
   "source": [
    "mode=\"cv\"\n",
    "hct=10\n",
    "test_ratio=None\n",
    "val_ratio=None\n",
    "folds=5\n",
    "results = {}\n",
    "dataset_names = [\"eucalyptus\", \"Midwest_survey\", \"hpc-job-scheduling\", \"video-game-sales\", \"okcupid-stem\", \"Diabetes130US\"]\n",
    "\n",
    "\n",
    "loss_use = lambda: tf.keras.losses.CategoricalCrossentropy\n",
    "target= \"categorical\"\n",
    "batch_size=512\n",
    "epochs = 200\n",
    "early_stopping = 5\n",
    "model_name = \"ResNet\"\n",
    "embed_dims_method = \"AutoGluon\"\n",
    "\n",
    "results = {}\n",
    "\n",
    "#######################################\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    print(f\"Start training procedure for {dataset_name}\")\n",
    "    data_path = f\"{mode}_RS{RS}_hct{hct}\"\n",
    "    if mode == \"cv\":\n",
    "        data_path += f\"_{folds}folds\"\n",
    "    elif mode == \"train_test\":\n",
    "        data_path += f\"_split{1-test_ratio*100}-{test_ratio*100}\"\n",
    "    elif mode == \"train_val_test\":\n",
    "        data_path += f\"_split{round(100-(test_ratio+val_ratio)*100)}-{round(test_ratio*100)}-{round(val_ratio*100)}\"\n",
    "\n",
    "    # If no data_dict exists, run preprocessing, else load data_dict\n",
    "    if not os.path.exists(f\"../data/prepared/{dataset_name}/\"+data_path+\"/data_dict.pickle\"):\n",
    "        dataset_preprocessing.process_dataset(dataset_name, target, mode, RS, hct, test_ratio, val_ratio, folds)\n",
    "    with open(f\"../data/prepared/{dataset_name}/{data_path}/data_dict.pickle\", 'rb') as handle:\n",
    "            data_dict = pickle.load(handle)\n",
    "\n",
    "    z_cols = data_dict[\"z_cols\"]\n",
    "    \n",
    "    results[dataset_name] = {}\n",
    "    for fold_num in range(folds):\n",
    "        results[dataset_name][fold_num] = {}\n",
    "\n",
    "        print(f\"Fold no. {fold_num}\")\n",
    "        save_path = f\"../results/{dataset_name}/{data_path}/fold_{fold_num}/ResNet_10\"\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        \n",
    "        z_ohe_encoded_train = data_dict[f\"z_ohe_encoded_train_{fold_num}\"] \n",
    "        z_ohe_encoded_val = data_dict[f\"z_ohe_encoded_val_{fold_num}\"] \n",
    "        z_ohe_encoded_test = data_dict[f\"z_ohe_encoded_test_{fold_num}\"] \n",
    "\n",
    "        z_target_encoded_train = data_dict[f\"z_target_encoded_train_{fold_num}\"] \n",
    "        z_target_encoded_val = data_dict[f\"z_target_encoded_val_{fold_num}\"] \n",
    "        z_target_encoded_test = data_dict[f\"z_target_encoded_test_{fold_num}\"] \n",
    "        \n",
    "        target_encoding_time = data_dict[f\"target_encoding_time_{fold_num}\"]\n",
    "        ohe_encoding_time = data_dict[f\"ohe_encoding_time_{fold_num}\"]\n",
    "        \n",
    "        x_cols = data_dict[f\"X_train_{fold_num}\"].columns\n",
    "        X_train = data_dict[f\"X_train_{fold_num}\"]\n",
    "        Z_train = data_dict[f\"Z_train_{fold_num}\"]\n",
    "        y_train = data_dict[f\"y_train_{fold_num}\"]\n",
    "\n",
    "        X_val = data_dict[f\"X_val_{fold_num}\"]\n",
    "        Z_val = data_dict[f\"Z_val_{fold_num}\"]\n",
    "        y_val = data_dict[f\"y_val_{fold_num}\"]\n",
    "\n",
    "        X_test = data_dict[f\"X_test_{fold_num}\"]\n",
    "        Z_test = data_dict[f\"Z_test_{fold_num}\"]\n",
    "        y_test = data_dict[f\"y_test_{fold_num}\"]\n",
    "    \n",
    "        if not os.path.exists(f\"{save_path}/results_RS{RS}_{dataset_name}_iter{fold_num}.pickle\"):\n",
    "\n",
    "            tf.random.set_seed(RS+fold_num)\n",
    "            np.random.seed(RS+fold_num)\n",
    "\n",
    "            qs = np.max([tf.reduce_max(Z_train, axis=0),tf.reduce_max(Z_val, axis=0),tf.reduce_max(Z_test, axis=0)],axis=0)+1\n",
    "            \n",
    "            X_train = tf.convert_to_tensor(X_train)\n",
    "            Z_train = tf.convert_to_tensor(Z_train,dtype=tf.int32)\n",
    "            y_train = tf.convert_to_tensor(y_train)\n",
    "\n",
    "            X_val = tf.convert_to_tensor(X_val)\n",
    "            Z_val = tf.convert_to_tensor(Z_val,dtype=tf.int32)\n",
    "            y_val = tf.convert_to_tensor(y_val)\n",
    "\n",
    "            X_test = tf.convert_to_tensor(X_test)\n",
    "            Z_test = tf.convert_to_tensor(Z_test,dtype=tf.int32)\n",
    "            y_test = tf.convert_to_tensor(y_test)\n",
    "\n",
    "            if target == \"categorical\":\n",
    "                n_classes = np.unique(y_train).shape[0]\n",
    "            elif target==\"binary\":\n",
    "                n_classes = 1\n",
    "            \n",
    "            y_train = tf.one_hot(tf.cast(y_train,tf.int32),n_classes)\n",
    "            y_val = tf.one_hot(tf.cast(y_val,tf.int32),n_classes)\n",
    "            y_test = tf.one_hot(tf.cast(y_test,tf.int32),n_classes)\n",
    "            \n",
    "            ##### GMENN #####\n",
    "            d = X_train.shape[1] # columns\n",
    "            n = X_train.shape[0] # rows\n",
    "            num_outputs = n_classes\n",
    "            perc_numeric = d/(d+Z_train.shape[1])\n",
    "\n",
    "#             qs = np.max([tf.reduce_max(Z_train, axis=0),tf.reduce_max(Z_val, axis=0),tf.reduce_max(Z_test, axis=0)],axis=0)+1\n",
    "\n",
    "            set_seed(RS)\n",
    "\n",
    "            fe_model, optimizer = get_model(model_name=model_name, input_size=X_train.shape[1], \n",
    "                                              output_size=num_outputs, \n",
    "                                              target=target, \n",
    "                                              perc_numeric=perc_numeric, RS=RS)\n",
    "            \n",
    "            if dataset_name==\"eucalyptus\":\n",
    "                optimizer.learning_rate.assign(optimizer.learning_rate*10)\n",
    "        \n",
    "        \n",
    "            initial_stds = np.ones([len(qs),num_outputs]).astype(float).tolist()\n",
    "\n",
    "            me_model = MixedEffectsNetwork(X_train, Z_train, y_train, fe_model, \n",
    "                                           target=target, qs=qs,\n",
    "                                           initial_stds=initial_stds,\n",
    "                                          fe_loss_weight=1.,\n",
    "                                           mode=\"intercepts\",\n",
    "                                           early_stopping_fe=early_stopping,\n",
    "                                          )    \n",
    "\n",
    "            me_model.compile(\n",
    "                loss_class_me = loss_use()(),\n",
    "                loss_class_fe = loss_use()(),\n",
    "            #     metric_class_me = tf.keras.metrics.AUC(multi_label=True, name=\"auc_me\"),\n",
    "            #     metric_class_fe = tf.keras.metrics.AUC(multi_label=True, name=\"auc_fe\"),\n",
    "                optimizer=optimizer\n",
    "            )\n",
    "\n",
    "            mcmc = MCMCSamplingCallback(num_mcmc_samples=1,\n",
    "                                        perc_burnin=0.7,\n",
    "                                        warm_restart=None,\n",
    "                                        num_burnin_steps=1,\n",
    "                                        step_size = 0.1#initial_step_size,\n",
    "                                   )\n",
    "\n",
    "            print_metric = PrintMetrics(X_train, Z_train, y_train, X_val, Z_val, y_val)\n",
    "\n",
    "            start = time.time()\n",
    "            history = me_model.fit([X_train,Z_train], y_train,\n",
    "                         callbacks=[mcmc,\n",
    "                                    print_metric,\n",
    "                                    tf.keras.callbacks.EarlyStopping(monitor=\"me_auc_val\", patience=early_stopping, mode=\"max\")],\n",
    "                         epochs=epochs,\n",
    "                         validation_data=[[X_val,Z_val],y_val],\n",
    "                        batch_size=batch_size)\n",
    "\n",
    "            end = time.time()\n",
    "            fit_time_gmenn = round(end-start,2)\n",
    "\n",
    "            y_train_pred_gmenn, y_train_pred_gmenn_fe = me_model([X_train,Z_train])\n",
    "            y_val_pred_gmenn, y_val_pred_gmenn_fe = me_model([X_val,Z_val])\n",
    "            y_test_pred_gmenn, y_test_pred_gmenn_fe = me_model([X_test,Z_test])    \n",
    "\n",
    "            \n",
    "            ###### Prepare NN Training ######\n",
    "            metrics_use = []\n",
    "            if target ==\"binary\":\n",
    "                metrics_use.append(tf.keras.metrics.AUC(name=\"auc\"))\n",
    "                metrics_use.append(tf.keras.metrics.Accuracy(name=\"accuracy\"))\n",
    "                metrics_use.append(F1Score(num_classes=2, average=\"micro\", name=\"f1\"))\n",
    "                stop_mode = \"max\"\n",
    "                activation_layer = tf.keras.activations.sigmoid\n",
    "            elif target ==\"categorical\":\n",
    "                metrics_use.append(tf.keras.metrics.AUC(multi_label=True, name=\"auc\"))\n",
    "                metrics_use.append(tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"))\n",
    "                metrics_use.append(F1Score(num_classes=num_outputs, average=\"weighted\", name=\"f1\"))\n",
    "                stop_mode = \"max\"\n",
    "                activation_layer = tf.keras.activations.softmax\n",
    "            elif target == \"continuous\":\n",
    "                metrics_use.append(RSquare(name=\"r2\"))\n",
    "                metrics_use.append(tf.keras.metrics.MeanSquaredError(name=\"mse\"))\n",
    "                stop_mode = \"min\"            \n",
    "            \n",
    "            ##### Ignore #####\n",
    "            model_nn, optimizer = get_model(model_name=model_name, \n",
    "                                            input_size=X_train.shape[1], \n",
    "                                            output_size=num_outputs, \n",
    "                                            target=target, \n",
    "                                            perc_numeric=perc_numeric, RS=RS)\n",
    "            if dataset_name==\"eucalyptus\":\n",
    "                optimizer.learning_rate.assign(optimizer.learning_rate*10)\n",
    "\n",
    "            model_nn.build((n,d))\n",
    "            update_layer_activation(model=model_nn, activation=activation_layer)\n",
    "\n",
    "            model_nn.compile(loss=loss_use()(), optimizer=optimizer, metrics = metrics_use)\n",
    "\n",
    "            callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", patience=early_stopping, mode=stop_mode)\n",
    "\n",
    "            start = time.time()\n",
    "            history_nn = model_nn.fit(X_train, y_train,\n",
    "                         validation_data= [X_val, y_val],\n",
    "                         epochs=epochs, batch_size=batch_size, callbacks=[callback])\n",
    "            end = time.time()\n",
    "            fit_time_nn = round(end-start,2)\n",
    "\n",
    "            y_train_pred_nn = model_nn.predict(X_train ,batch_size=batch_size)\n",
    "            y_val_pred_nn = model_nn.predict(X_val ,batch_size=batch_size)\n",
    "            y_test_pred_nn = model_nn.predict(X_test ,batch_size=batch_size)\n",
    "\n",
    "            if target == \"binary\":\n",
    "                eval_res_train_nn = get_metrics(y_train[:,0], y_train_pred_nn, target=target)\n",
    "                eval_res_val_nn = get_metrics(y_val[:,0], y_val_pred_nn, target=target)\n",
    "                eval_res_test_nn = get_metrics(y_test[:,0], y_test_pred_nn, target=target)\n",
    "            elif target == \"categorical\":\n",
    "                eval_res_train_nn = get_metrics(y_train, y_train_pred_nn, target=target)\n",
    "                eval_res_val_nn = get_metrics(y_val, y_val_pred_nn, target=target)\n",
    "                eval_res_test_nn = get_metrics(y_test, y_test_pred_nn, target=target)\n",
    "\n",
    "            ##### Target Encoding #####\n",
    "            print(\"\\n Train Target Encoding Network\")\n",
    "            model_nn_te, optimizer = get_model(model_name=model_name, \n",
    "                                            input_size=np.append(X_train ,z_target_encoded_train, axis=1).shape[1], \n",
    "                                            output_size=num_outputs, \n",
    "                                            target=target, \n",
    "                                            perc_numeric=perc_numeric, RS=RS)\n",
    "            if dataset_name==\"eucalyptus\":\n",
    "                optimizer.learning_rate.assign(optimizer.learning_rate*10)\n",
    "            model_nn_te.build((n,np.append(X_train ,z_target_encoded_train, axis=1).shape[1]))\n",
    "            update_layer_activation(model=model_nn_te, activation=activation_layer)\n",
    "            model_nn_te.compile(loss=loss_use()(), optimizer=optimizer, metrics = metrics_use)\n",
    "            callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", patience=early_stopping, mode=stop_mode)\n",
    "\n",
    "            start = time.time()\n",
    "            history_nn_te = model_nn_te.fit(np.append(X_train ,z_target_encoded_train, axis=1), y_train,\n",
    "                         validation_data= [np.append(X_val ,z_target_encoded_val, axis=1), y_val],\n",
    "                         epochs=epochs, batch_size=batch_size, callbacks=[callback])\n",
    "            end = time.time()\n",
    "            fit_time_te = round(end-start,2)+target_encoding_time\n",
    "\n",
    "            y_train_pred_nn_te = model_nn_te.predict(np.append(X_train ,z_target_encoded_train, axis=1) ,batch_size=batch_size)\n",
    "            y_val_pred_nn_te = model_nn_te.predict(np.append(X_val ,z_target_encoded_val, axis=1) ,batch_size=batch_size)\n",
    "            y_test_pred_nn_te = model_nn_te.predict(np.append(X_test ,z_target_encoded_test, axis=1) ,batch_size=batch_size)\n",
    "\n",
    "            if target == \"binary\":\n",
    "                eval_res_train_nn_te = get_metrics(y_train[:,0], y_train_pred_nn_te, target=target)\n",
    "                eval_res_val_nn_te = get_metrics(y_val[:,0], y_val_pred_nn_te, target=target)\n",
    "                eval_res_test_nn_te = get_metrics(y_test[:,0], y_test_pred_nn_te, target=target)\n",
    "            elif target == \"categorical\":\n",
    "                eval_res_train_nn_te = get_metrics(y_train, y_train_pred_nn_te, target=target)\n",
    "                eval_res_val_nn_te = get_metrics(y_val, y_val_pred_nn_te, target=target)\n",
    "                eval_res_test_nn_te = get_metrics(y_test, y_test_pred_nn_te, target=target)\n",
    "\n",
    "            ##### OHE #####\n",
    "            print(\"\\n Train OHE Network\")\n",
    "            model_nn_ohe, optimizer = get_model(model_name=model_name, \n",
    "                                            input_size=np.append(X_train ,z_ohe_encoded_train, axis=1).shape[1], \n",
    "                                            output_size=num_outputs, \n",
    "                                            target=target, \n",
    "                                            perc_numeric=perc_numeric, RS=RS)\n",
    "            if dataset_name==\"eucalyptus\":\n",
    "                optimizer.learning_rate.assign(optimizer.learning_rate*10)\n",
    "            model_nn_ohe.build((n,np.append(X_train ,z_ohe_encoded_train, axis=1).shape[1]))\n",
    "            update_layer_activation(model=model_nn_ohe, activation=activation_layer)\n",
    "            model_nn_ohe.compile(loss=loss_use()(), optimizer=optimizer, metrics = metrics_use)\n",
    "            callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", patience=early_stopping, mode=stop_mode)\n",
    "\n",
    "            start = time.time()\n",
    "            history_nn_ohe = model_nn_ohe.fit(np.append(X_train ,z_ohe_encoded_train, axis=1), y_train,\n",
    "                         validation_data= [np.append(X_val ,z_ohe_encoded_val, axis=1), y_val],\n",
    "                         epochs=epochs, batch_size=batch_size, callbacks=[callback])\n",
    "            end = time.time()\n",
    "            fit_time_ohe = round(end-start,2)+ohe_encoding_time\n",
    "\n",
    "            y_train_pred_nn_ohe = model_nn_ohe.predict(np.append(X_train ,z_ohe_encoded_train, axis=1), batch_size=batch_size)\n",
    "            y_val_pred_nn_ohe = model_nn_ohe.predict(np.append(X_val ,z_ohe_encoded_val, axis=1), batch_size=batch_size)\n",
    "            y_test_pred_nn_ohe = model_nn_ohe.predict(np.append(X_test ,z_ohe_encoded_test, axis=1), batch_size=batch_size)\n",
    "            \n",
    "            if target == \"binary\":\n",
    "                eval_res_train_nn_ohe = get_metrics(y_train[:,0], y_train_pred_nn_ohe, target=target)\n",
    "                eval_res_val_nn_ohe = get_metrics(y_val[:,0], y_val_pred_nn_ohe, target=target)\n",
    "                eval_res_test_nn_ohe = get_metrics(y_test[:,0], y_test_pred_nn_ohe, target=target)            \n",
    "            elif target == \"categorical\":\n",
    "                eval_res_train_nn_ohe = get_metrics(y_train, y_train_pred_nn_ohe, target=target)\n",
    "                eval_res_val_nn_ohe = get_metrics(y_val, y_val_pred_nn_ohe, target=target)\n",
    "                eval_res_test_nn_ohe = get_metrics(y_test, y_test_pred_nn_ohe, target=target)\n",
    "                \n",
    "            ##### Embedding #####\n",
    "            print(\"\\n Embedding Estimate Network\")\n",
    "\n",
    "            if embed_dims_method==\"sqrt\":\n",
    "                embed_dims = [int(np.sqrt(q)) for q in qs]\n",
    "            elif embed_dims_method==\"AutoGluon\":\n",
    "                embed_dims = [int(np.max([100, np.round(1.6*q**0.56)])) for q in qs]\n",
    "            else:\n",
    "                embed_dims = [10 for q in qs]\n",
    "\n",
    "            input_layer = Input(shape=(d,))\n",
    "\n",
    "            # Define embedding layers\n",
    "            embed_inputs = []\n",
    "            embedding_layers = []\n",
    "            for q_num in range(len(qs)):\n",
    "                Z_input_layer = Input(shape=(1,))\n",
    "                embedding_layer = Embedding(qs[q_num], embed_dims[q_num], input_length=1)(Z_input_layer)\n",
    "                embedding_layer = Reshape(target_shape=(embed_dims[q_num],))(embedding_layer)\n",
    "\n",
    "                embed_inputs.append(Z_input_layer)\n",
    "                embedding_layers.append(embedding_layer)\n",
    "\n",
    "            ### Get model layer dimensions\n",
    "            min_numeric_embed_dim = 32\n",
    "            max_numeric_embed_dim = 2056\n",
    "            max_layer_width = 2056\n",
    "            # Main dense model\n",
    "            if target == \"continuous\":\n",
    "                default_layer_sizes = [256,\n",
    "                                       128]  # overall network will have 4 layers. Input layer, 256-unit hidden layer, 128-unit hidden layer, output layer.\n",
    "            else:\n",
    "                default_sizes = [256, 128]  # will be scaled adaptively\n",
    "                # base_size = max(1, min(num_net_outputs, 20)/2.0) # scale layer width based on number of classes\n",
    "                base_size = max(1, min(num_outputs,\n",
    "                                       100) / 50)  # TODO: Updated because it improved model quality and made training far faster\n",
    "                default_layer_sizes = [defaultsize * base_size for defaultsize in default_sizes]\n",
    "            layer_expansion_factor = 1  # TODO: consider scaling based on num_rows, eg: layer_expansion_factor = 2-np.exp(-max(0,train_dataset.num_examples-10000))\n",
    "            first_layer_width = int(min(max_layer_width, layer_expansion_factor * default_layer_sizes[0]))\n",
    "\n",
    "            # numeric embed dim\n",
    "            vector_dim = 0  # total dimensionality of vector features (I think those should be transformed string features, which we don't have)\n",
    "            prop_vector_features = perc_numeric  # Fraction of features that are numeric\n",
    "            numeric_embedding_size = int(min(max_numeric_embed_dim,\n",
    "                                             max(min_numeric_embed_dim,\n",
    "                                                 first_layer_width * prop_vector_features * np.log10(vector_dim + 10))))\n",
    "\n",
    "\n",
    "            numeric_embedding = Dense(numeric_embedding_size, activation=\"relu\")(input_layer)\n",
    "\n",
    "            concat = Concatenate()([numeric_embedding] + embedding_layers)\n",
    "\n",
    "            base_model, optimizer = get_model(model_name=model_name, \n",
    "                                              input_size=numeric_embedding_size + sum(embed_dims), \n",
    "                                              output_size=num_outputs, target=target,\n",
    "                                              perc_numeric=perc_numeric, RS=RS)\n",
    "\n",
    "            if dataset_name==\"eucalyptus\":\n",
    "                optimizer.learning_rate.assign(optimizer.learning_rate*10)\n",
    "            base_model.build((n, numeric_embedding_size + sum(embed_dims)))\n",
    "            update_layer_activation(model=base_model, activation=activation_layer)\n",
    "\n",
    "            layers = base_model(concat)\n",
    "\n",
    "            model_embed = Model(inputs=[input_layer] + embed_inputs, outputs=layers)\n",
    "\n",
    "\n",
    "            model_embed.compile(loss=loss_use()(), optimizer=optimizer, metrics = metrics_use)\n",
    "            callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", patience=early_stopping, mode=stop_mode)\n",
    "\n",
    "            start = time.time()\n",
    "            history_nn_embed = model_embed.fit([X_train] + [Z_train[: ,q_num] for q_num in range(len(qs))], y_train,\n",
    "                            validation_data=[[X_val] + [Z_val[: ,q_num] for q_num in range(len(qs))], y_val],\n",
    "                            epochs=epochs, batch_size=batch_size, callbacks=[callback])\n",
    "            end = time.time()\n",
    "            fit_time_embed = round(end-start,2)\n",
    "\n",
    "            y_train_pred_embed = model_embed.predict([X_train] + [Z_train[: ,q_num] for q_num in range(len(qs))]\n",
    "                                                     ,batch_size=batch_size)\n",
    "            y_val_pred_embed = model_embed.predict([X_val] + [Z_val[: ,q_num] for q_num in range(len(qs))]\n",
    "                                                    ,batch_size=batch_size)\n",
    "            y_test_pred_embed = model_embed.predict([X_test] + [Z_test[: ,q_num] for q_num in range(len(qs))]\n",
    "                                                    ,batch_size=batch_size)\n",
    "\n",
    "            if target == \"binary\":\n",
    "                eval_res_train_embed = get_metrics(y_train[:,0], y_train_pred_embed, target=target)\n",
    "                eval_res_val_embed = get_metrics(y_val[:,0], y_val_pred_embed, target=target)\n",
    "                eval_res_test_embed = get_metrics(y_test[:,0], y_test_pred_embed, target=target)\n",
    "            elif target == \"categorical\":\n",
    "                eval_res_train_embed = get_metrics(y_train, y_train_pred_embed, target=target)\n",
    "                eval_res_val_embed = get_metrics(y_val, y_val_pred_embed, target=target)\n",
    "                eval_res_test_embed = get_metrics(y_test, y_test_pred_embed, target=target)\n",
    "\n",
    "            eval_res_train_embed, eval_res_test_embed        \n",
    "\n",
    "\n",
    "\n",
    "            ##### Document Results #####\n",
    "            \n",
    "            results[dataset_name][fold_num][\"histories\"] = {\"GMENN\": history.history,\n",
    "                                                       \"Ignore\": history_nn.history,\n",
    "                                                       \"TE\": history_nn_te.history,\n",
    "                                                       \"OHE\": history_nn_ohe.history,\n",
    "                                                       \"Embedding\": history_nn_embed.history,\n",
    "                                                      }\n",
    "            \n",
    "            results[dataset_name][fold_num][\"predictions\"] = {\"GMENN\": [y_train_pred_gmenn, y_val_pred_gmenn, y_test_pred_gmenn],\n",
    "                                                        \"GMENN (FE)\": [y_train_pred_gmenn_fe, y_val_pred_gmenn_fe, y_test_pred_gmenn_fe],\n",
    "                                                        \"Ignore\": [y_train_pred_nn, y_val_pred_nn, y_test_pred_nn],\n",
    "                                                        \"TE\": [y_train_pred_nn_te, y_val_pred_nn_te, y_test_pred_nn_te],\n",
    "                                                        \"OHE\": [y_train_pred_nn_ohe, y_val_pred_nn_ohe, y_test_pred_nn_ohe],\n",
    "                                                        \"Embedding\": [y_train_pred_embed, y_val_pred_embed, y_test_pred_embed],\n",
    "                                                     }\n",
    "            \n",
    "            results[dataset_name][fold_num][\"times\"] = {\"GMENN\": fit_time_gmenn,\n",
    "                                                   \"Ignore\": fit_time_nn,\n",
    "                                                   \"TE\": fit_time_te,\n",
    "                                                   \"OHE\": fit_time_ohe,\n",
    "                                                   \"Embedding\": fit_time_embed,\n",
    "                                                      }\n",
    "            \n",
    "            results[dataset_name][fold_num][\"other_info\"] = {\n",
    "                \"GMENN\": {\n",
    "                    \"_stddev_z\": np.array([i.numpy() for i in me_model.data_model._stddev_z]),\n",
    "                    \"acceptance_rates\": np.array(me_model.acceptance_rates),\n",
    "                    \"random_effects\": me_model.mean_samples,\n",
    "                    \"all_samples\": me_model.all_samples,\n",
    "                    \"stds\": me_model.stds\n",
    "                },\n",
    "            }\n",
    "            \n",
    "            \n",
    "            with open(f\"{save_path}//results_RS{RS}_{dataset_name}_iter{fold_num}.pickle\", 'wb') as handle:\n",
    "                pickle.dump(results[dataset_name][fold_num], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "            \n",
    "            del X_train, X_val, X_test, y_train, y_val, y_test\n",
    "            del z_target_encoded_train, z_target_encoded_val, z_target_encoded_test\n",
    "            del z_ohe_encoded_train, z_ohe_encoded_val, z_ohe_encoded_test\n",
    "            \n",
    "            gc.collect()\n",
    "        else:\n",
    "            print(f\"Load results for dataset {dataset_name}, iteration={fold_num}\")\n",
    "            with open(f\"{save_path}/results_RS{RS}_{dataset_name}_iter{fold_num}.pickle\", 'rb') as handle:\n",
    "                results[dataset_name][fold_num] = pickle.load(handle)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c02f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63d93847",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dcfb167",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 17:28:03.559391: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "models = [\"GMENN\", \"TE\", \"OHE\", \"Embedding\",\"Ignore\"]\n",
    "\n",
    "results_perf = {dataset_name: {num: {model: {}  for model in models} for num in range(folds)} for dataset_name in dataset_names}\n",
    "for dataset_name in dataset_names:\n",
    "    try:\n",
    "        with open(f\"../data/prepared/{dataset_name}/{data_path}/data_dict.pickle\", 'rb') as handle:\n",
    "            data_dict = pickle.load(handle)        \n",
    "    except:\n",
    "        print(f\"dataset {dataset_name} not found\") \n",
    "    for num in range(folds):\n",
    "        y_test = data_dict[f\"y_test_{num}\"]\n",
    "        n_classes = np.unique(y_test).shape[0]\n",
    "        y_test = tf.one_hot(data_dict[f\"y_test_{num}\"],n_classes)\n",
    "        for model in models:\n",
    "            try:\n",
    "                y_pred = results[dataset_name][num][\"predictions\"][model][2]\n",
    "\n",
    "                results_perf[dataset_name][num][model] = get_metrics(y_test,y_pred,target)\n",
    "                results_perf[dataset_name][num][model][\"Time\"] = results[dataset_name][num][\"times\"][model]\n",
    "            except:\n",
    "                print(f\"Set nan for {dataset_name}, {num}\")\n",
    "                results_perf[dataset_name][num][model] = {\"Accuracy\": np.nan,\n",
    "                                                          \"AUROC\": np.nan,\n",
    "                                                          \"F1\": np.nan,\n",
    "                                                          \"Time\": np.nan}\n",
    "#                 print(f\"Didnt work for {dataset_name}, {num}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3246b11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GMENN</th>\n",
       "      <th>TE</th>\n",
       "      <th>OHE</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Ignore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eucalyptus</th>\n",
       "      <td>0.89 (0.021)</td>\n",
       "      <td>0.89 (0.021)</td>\n",
       "      <td>0.9 (0.026)</td>\n",
       "      <td>0.91 (0.022)</td>\n",
       "      <td>0.91 (0.021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Midwest_survey</th>\n",
       "      <td>0.84 (0.024)</td>\n",
       "      <td>0.76 (0.008)</td>\n",
       "      <td>0.8 (0.013)</td>\n",
       "      <td>0.85 (0.015)</td>\n",
       "      <td>0.78 (0.009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hpc-job-scheduling</th>\n",
       "      <td>0.88 (0.009)</td>\n",
       "      <td>0.81 (0.021)</td>\n",
       "      <td>0.89 (0.009)</td>\n",
       "      <td>0.91 (0.01)</td>\n",
       "      <td>0.79 (0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video-game-sales</th>\n",
       "      <td>0.77 (0.008)</td>\n",
       "      <td>0.63 (0.016)</td>\n",
       "      <td>0.76 (0.005)</td>\n",
       "      <td>0.77 (0.01)</td>\n",
       "      <td>0.67 (0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>okcupid-stem</th>\n",
       "      <td>0.8 (0.005)</td>\n",
       "      <td>0.67 (0.017)</td>\n",
       "      <td>0.82 (0.004)</td>\n",
       "      <td>0.81 (0.005)</td>\n",
       "      <td>0.74 (0.005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes130US</th>\n",
       "      <td>0.67 (0.007)</td>\n",
       "      <td>0.63 (0.008)</td>\n",
       "      <td>0.68 (0.003)</td>\n",
       "      <td>0.68 (0.003)</td>\n",
       "      <td>0.64 (0.005)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           GMENN            TE           OHE     Embedding  \\\n",
       "eucalyptus          0.89 (0.021)  0.89 (0.021)   0.9 (0.026)  0.91 (0.022)   \n",
       "Midwest_survey      0.84 (0.024)  0.76 (0.008)   0.8 (0.013)  0.85 (0.015)   \n",
       "hpc-job-scheduling  0.88 (0.009)  0.81 (0.021)  0.89 (0.009)   0.91 (0.01)   \n",
       "video-game-sales    0.77 (0.008)  0.63 (0.016)  0.76 (0.005)   0.77 (0.01)   \n",
       "okcupid-stem         0.8 (0.005)  0.67 (0.017)  0.82 (0.004)  0.81 (0.005)   \n",
       "Diabetes130US       0.67 (0.007)  0.63 (0.008)  0.68 (0.003)  0.68 (0.003)   \n",
       "\n",
       "                          Ignore  \n",
       "eucalyptus          0.91 (0.021)  \n",
       "Midwest_survey      0.78 (0.009)  \n",
       "hpc-job-scheduling   0.79 (0.01)  \n",
       "video-game-sales     0.67 (0.01)  \n",
       "okcupid-stem        0.74 (0.005)  \n",
       "Diabetes130US       0.64 (0.005)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [\"GMENN\", \"TE\", \"OHE\", \"Embedding\", \"Ignore\"]\n",
    "\n",
    "metric = \"AUROC\"\n",
    "\n",
    "#####\n",
    "dataset_res_dict = {}\n",
    "best_models = {}\n",
    "t_test_results = {}\n",
    "\n",
    "round_mean_at = 2\n",
    "round_std_at = 3\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    dataset_models = list(results_perf[dataset_name][0].keys())\n",
    "    use_df = pd.DataFrame([pd.DataFrame(results_perf[dataset_name][fold_num]).loc[metric,models] for fold_num in results_perf[dataset_name].keys()],index=results_perf[dataset_name].keys())\n",
    "    \n",
    "    df_mean = pd.DataFrame(use_df.mean(axis=0).round(round_mean_at).astype(str) + \" (\" + use_df.std(axis=0).round(round_std_at).astype(str) + \")\").transpose()\n",
    "    model_dict = {i: df_mean[i].values[0] for i in df_mean.columns}\n",
    "    dataset_res_dict[dataset_name] = model_dict\n",
    "    \n",
    "    best_models[dataset_name] = use_df.columns[use_df.mean(axis=0).argmax()]\n",
    "\n",
    "    t_test_res = np.array([stats.ttest_rel(use_df[best_models[dataset_name]].values, use_df[model].values)[1] if model in dataset_models else 0 for model in models]).round(3)\n",
    "    t_test_res[np.isnan(t_test_res)] = 1.\n",
    "    t_test_results[dataset_name] = t_test_res\n",
    "    \n",
    "res_df = pd.DataFrame(dataset_res_dict).transpose()\n",
    "    \n",
    "def negative_bold(val):\n",
    "    i = np.where(val.name==np.array(models))[0][0]\n",
    "    return [\"font-weight: bold\"  if t_test_results[dataset_name][i]>=0.05 else \"\" for dataset_name in val.keys()]\n",
    "    # Case without transpose:\n",
    "#     return [\"font-weight: bold\"  if t_test_results[val.name][i]>=0.05 else \"\" for i in range(len(val))]\n",
    "\n",
    "# res_df.style.apply(negative_bold)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcb9dd00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GMENN</th>\n",
       "      <th>TE</th>\n",
       "      <th>OHE</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Ignore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eucalyptus</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>font-weight: bold</td>\n",
       "      <td>font-weight: bold</td>\n",
       "      <td>font-weight: bold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Midwest_survey</th>\n",
       "      <td>font-weight: bold</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>font-weight: bold</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hpc-job-scheduling</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>font-weight: bold</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video-game-sales</th>\n",
       "      <td>font-weight: bold</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>font-weight: bold</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>okcupid-stem</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>font-weight: bold</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes130US</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>font-weight: bold</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                GMENN TE                OHE  \\\n",
       "eucalyptus                                font-weight: bold   \n",
       "Midwest_survey      font-weight: bold                         \n",
       "hpc-job-scheduling                                            \n",
       "video-game-sales    font-weight: bold                         \n",
       "okcupid-stem                              font-weight: bold   \n",
       "Diabetes130US                             font-weight: bold   \n",
       "\n",
       "                            Embedding             Ignore  \n",
       "eucalyptus          font-weight: bold  font-weight: bold  \n",
       "Midwest_survey      font-weight: bold                     \n",
       "hpc-job-scheduling  font-weight: bold                     \n",
       "video-game-sales    font-weight: bold                     \n",
       "okcupid-stem                                              \n",
       "Diabetes130US                                             "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.apply(negative_bold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddb74cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "{} &         GMENN &        Ignore &            TE &           OHE &     Embedding \\\\\n",
      "\\midrule\n",
      "eucalyptus         &  0.89 (0.021) &  0.89 (0.021) &   0.9 (0.026) &  0.91 (0.022) &  0.91 (0.021) \\\\\n",
      "Midwest\\_survey     &  0.84 (0.024) &  0.76 (0.008) &   0.8 (0.013) &  0.85 (0.015) &  0.78 (0.009) \\\\\n",
      "hpc-job-scheduling &  0.88 (0.009) &  0.81 (0.021) &  0.89 (0.009) &   0.91 (0.01) &   0.79 (0.01) \\\\\n",
      "video-game-sales   &  0.77 (0.008) &  0.63 (0.016) &  0.76 (0.005) &   0.77 (0.01) &   0.67 (0.01) \\\\\n",
      "okcupid-stem       &   0.8 (0.005) &  0.67 (0.017) &  0.82 (0.004) &  0.81 (0.005) &  0.74 (0.005) \\\\\n",
      "Diabetes130US      &  0.67 (0.007) &  0.63 (0.008) &  0.68 (0.003) &  0.68 (0.003) &  0.64 (0.005) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_df.columns = [\"GMENN\", \"Ignore\",  \"TE\", \"OHE\", \"Embedding\"]\n",
    "print(res_df.to_latex(index=True))\n",
    "# res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d68f4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMENN        0.46\n",
      "TE           0.21\n",
      "OHE          0.58\n",
      "Embedding    0.75\n",
      "Ignore       0.28\n",
      "dtype: float64\n",
      "GMENN        2.67\n",
      "TE           4.83\n",
      "OHE          2.17\n",
      "Embedding    1.50\n",
      "Ignore       3.83\n",
      "dtype: float64\n",
      "GMENN        0.0146\n",
      "TE           0.0921\n",
      "OHE          0.0152\n",
      "Embedding    0.0015\n",
      "Ignore       0.0679\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eucalyptus</th>\n",
       "      <th>Midwest_survey</th>\n",
       "      <th>hpc-job-scheduling</th>\n",
       "      <th>video-game-sales</th>\n",
       "      <th>okcupid-stem</th>\n",
       "      <th>Diabetes130US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GMENN</th>\n",
       "      <td>0.894152</td>\n",
       "      <td>0.838486</td>\n",
       "      <td>0.881305</td>\n",
       "      <td>0.773724</td>\n",
       "      <td>0.799715</td>\n",
       "      <td>0.668554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TE</th>\n",
       "      <td>0.890051</td>\n",
       "      <td>0.764253</td>\n",
       "      <td>0.807443</td>\n",
       "      <td>0.627644</td>\n",
       "      <td>0.667454</td>\n",
       "      <td>0.634482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OHE</th>\n",
       "      <td>0.903740</td>\n",
       "      <td>0.804891</td>\n",
       "      <td>0.886275</td>\n",
       "      <td>0.762067</td>\n",
       "      <td>0.815571</td>\n",
       "      <td>0.680065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embedding</th>\n",
       "      <td>0.913796</td>\n",
       "      <td>0.854892</td>\n",
       "      <td>0.905643</td>\n",
       "      <td>0.772525</td>\n",
       "      <td>0.809206</td>\n",
       "      <td>0.678419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ignore</th>\n",
       "      <td>0.907980</td>\n",
       "      <td>0.779084</td>\n",
       "      <td>0.791452</td>\n",
       "      <td>0.673818</td>\n",
       "      <td>0.740299</td>\n",
       "      <td>0.643510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           eucalyptus  Midwest_survey  hpc-job-scheduling  video-game-sales  \\\n",
       "GMENN        0.894152        0.838486            0.881305          0.773724   \n",
       "TE           0.890051        0.764253            0.807443          0.627644   \n",
       "OHE          0.903740        0.804891            0.886275          0.762067   \n",
       "Embedding    0.913796        0.854892            0.905643          0.772525   \n",
       "Ignore       0.907980        0.779084            0.791452          0.673818   \n",
       "\n",
       "           okcupid-stem  Diabetes130US  \n",
       "GMENN          0.799715       0.668554  \n",
       "TE             0.667454       0.634482  \n",
       "OHE            0.815571       0.680065  \n",
       "Embedding      0.809206       0.678419  \n",
       "Ignore         0.740299       0.643510  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = {}\n",
    "for dataset_name in dataset_names:\n",
    "    dataset_models = list(results_perf[dataset_name][0].keys())\n",
    "    use_df = pd.DataFrame([pd.DataFrame(results_perf[dataset_name][fold_num]).loc[metric,models] for fold_num in results_perf[dataset_name].keys()],index=results_perf[dataset_name].keys())\n",
    "    dataset_df[dataset_name] = use_df\n",
    "    \n",
    "mean_df = pd.DataFrame({dataset_name: dataset_df[dataset_name].mean(axis=0) for dataset_name in dataset_names})\n",
    "\n",
    "# Mean reciprocal rank\n",
    "print(np.mean((1/mean_df.rank(axis=0,ascending=False)),axis=1).round(2))\n",
    "\n",
    "# Mean rank\n",
    "print(np.mean((mean_df.rank(axis=0,ascending=False)),axis=1).round(2))\n",
    "\n",
    "# Average distance to best\n",
    "print(mean_df.apply(lambda x: np.abs(x-np.max(x)),axis=0).mean(axis=1).round(4))\n",
    "\n",
    "mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec490dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8941517 , 0.83848622, 0.88130544, 0.77372364, 0.79971493,\n",
       "        0.66855443],\n",
       "       [0.89005096, 0.76425345, 0.80744309, 0.62764355, 0.66745428,\n",
       "        0.63448187],\n",
       "       [0.90373965, 0.80489136, 0.88627461, 0.76206654, 0.81557086,\n",
       "        0.68006545],\n",
       "       [0.91379603, 0.85489233, 0.90564332, 0.77252502, 0.80920638,\n",
       "        0.67841862],\n",
       "       [0.90798047, 0.77908409, 0.79145216, 0.67381812, 0.74029944,\n",
       "        0.64351008]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(mean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "304b9fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0003, 1e-06)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3e-4, 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d77f0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "{} &  GMENN &    TE &   OHE &  Embedding &  Ignore \\\\\n",
      "\\midrule\n",
      "0 &   0.46 &  0.21 &  0.58 &       0.75 &    0.28 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(np.mean((1/mean_df.rank(axis=0,ascending=False)),axis=1)).transpose().round(2).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0d4d2b",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd49a259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GMENN</th>\n",
       "      <th>TE</th>\n",
       "      <th>OHE</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Ignore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eucalyptus</th>\n",
       "      <td>16.39 (17.547)</td>\n",
       "      <td>1.3 (0.273)</td>\n",
       "      <td>1.63 (0.297)</td>\n",
       "      <td>1.15 (0.132)</td>\n",
       "      <td>1.57 (0.208)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Midwest_survey</th>\n",
       "      <td>11.08 (4.698)</td>\n",
       "      <td>2.85 (0.446)</td>\n",
       "      <td>3.28 (0.47)</td>\n",
       "      <td>3.88 (0.398)</td>\n",
       "      <td>3.45 (0.423)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hpc-job-scheduling</th>\n",
       "      <td>30.73 (40.96)</td>\n",
       "      <td>1.82 (0.153)</td>\n",
       "      <td>3.11 (0.825)</td>\n",
       "      <td>2.45 (0.664)</td>\n",
       "      <td>2.2 (0.532)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video-game-sales</th>\n",
       "      <td>5.36 (1.804)</td>\n",
       "      <td>1.71 (0.602)</td>\n",
       "      <td>6.26 (0.493)</td>\n",
       "      <td>3.85 (1.098)</td>\n",
       "      <td>4.7 (1.274)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>okcupid-stem</th>\n",
       "      <td>8.73 (1.406)</td>\n",
       "      <td>1.06 (0.121)</td>\n",
       "      <td>5.31 (0.738)</td>\n",
       "      <td>2.09 (0.171)</td>\n",
       "      <td>7.2 (1.358)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes130US</th>\n",
       "      <td>21.97 (7.297)</td>\n",
       "      <td>1.64 (0.467)</td>\n",
       "      <td>3.16 (0.543)</td>\n",
       "      <td>2.11 (0.168)</td>\n",
       "      <td>6.33 (0.869)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             GMENN            TE           OHE     Embedding  \\\n",
       "eucalyptus          16.39 (17.547)   1.3 (0.273)  1.63 (0.297)  1.15 (0.132)   \n",
       "Midwest_survey       11.08 (4.698)  2.85 (0.446)   3.28 (0.47)  3.88 (0.398)   \n",
       "hpc-job-scheduling   30.73 (40.96)  1.82 (0.153)  3.11 (0.825)  2.45 (0.664)   \n",
       "video-game-sales      5.36 (1.804)  1.71 (0.602)  6.26 (0.493)  3.85 (1.098)   \n",
       "okcupid-stem          8.73 (1.406)  1.06 (0.121)  5.31 (0.738)  2.09 (0.171)   \n",
       "Diabetes130US        21.97 (7.297)  1.64 (0.467)  3.16 (0.543)  2.11 (0.168)   \n",
       "\n",
       "                          Ignore  \n",
       "eucalyptus          1.57 (0.208)  \n",
       "Midwest_survey      3.45 (0.423)  \n",
       "hpc-job-scheduling   2.2 (0.532)  \n",
       "video-game-sales     4.7 (1.274)  \n",
       "okcupid-stem         7.2 (1.358)  \n",
       "Diabetes130US       6.33 (0.869)  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [\"GMENN\", \"TE\", \"OHE\", \"Embedding\", \"Ignore\"]\n",
    "metric = \"Time\"\n",
    "\n",
    "#####\n",
    "dataset_res_dict = {}\n",
    "best_models = {}\n",
    "t_test_results = {}\n",
    "\n",
    "round_mean_at = 2\n",
    "round_std_at = 3\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    dataset_models = list(results_perf[dataset_name][0].keys())\n",
    "    use_df = pd.DataFrame([pd.DataFrame(results_perf[dataset_name][fold_num]).loc[metric,models] for fold_num in results_perf[dataset_name].keys()],index=results_perf[dataset_name].keys())/60\n",
    "    \n",
    "    df_mean = pd.DataFrame(use_df.mean(axis=0).round(round_mean_at).astype(str) + \" (\" + use_df.std(axis=0).round(round_std_at).astype(str) + \")\").transpose()\n",
    "    model_dict = {i: df_mean[i].values[0] for i in df_mean.columns}\n",
    "    dataset_res_dict[dataset_name] = model_dict\n",
    "    \n",
    "    best_models[dataset_name] = use_df.columns[use_df.mean(axis=0).argmin()]\n",
    "\n",
    "    t_test_res = np.array([stats.ttest_rel(use_df[best_models[dataset_name]].values, use_df[model].values)[1] if model in dataset_models else 0 for model in models]).round(3)\n",
    "    t_test_res[np.isnan(t_test_res)] = 1.\n",
    "    t_test_results[dataset_name] = t_test_res\n",
    "    \n",
    "res_df = pd.DataFrame(dataset_res_dict).transpose()\n",
    "    \n",
    "def negative_bold(val):\n",
    "    i = np.where(val.name==np.array(models))[0][0]\n",
    "    return [\"font-weight: bold\"  if t_test_results[dataset_name][i]>=0.05 else \"\" for dataset_name in val.keys()]\n",
    "    # Case without transpose:\n",
    "#     return [\"font-weight: bold\"  if t_test_results[val.name][i]>=0.05 else \"\" for i in range(len(val))]\n",
    "\n",
    "# res_df.style.apply(negative_bold)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d068c049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eucalyptus': array([0.123, 0.167, 0.012, 1.   , 0.003]),\n",
       " 'Midwest_survey': array([0.02 , 1.   , 0.267, 0.049, 0.03 ]),\n",
       " 'hpc-job-scheduling': array([0.189, 1.   , 0.016, 0.083, 0.192]),\n",
       " 'video-game-sales': array([0.018, 1.   , 0.   , 0.042, 0.005]),\n",
       " 'okcupid-stem': array([0.   , 1.   , 0.   , 0.   , 0.001]),\n",
       " 'Diabetes130US': array([0.003, 1.   , 0.012, 0.025, 0.   ])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0310de36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GMENN</th>\n",
       "      <th>TE</th>\n",
       "      <th>OHE</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Ignore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eucalyptus</th>\n",
       "      <td>font-weight: bold</td>\n",
       "      <td>font-weight: bold</td>\n",
       "      <td></td>\n",
       "      <td>font-weight: bold</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Midwest_survey</th>\n",
       "      <td></td>\n",
       "      <td>font-weight: bold</td>\n",
       "      <td>font-weight: bold</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hpc-job-scheduling</th>\n",
       "      <td>font-weight: bold</td>\n",
       "      <td>font-weight: bold</td>\n",
       "      <td></td>\n",
       "      <td>font-weight: bold</td>\n",
       "      <td>font-weight: bold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video-game-sales</th>\n",
       "      <td></td>\n",
       "      <td>font-weight: bold</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>okcupid-stem</th>\n",
       "      <td></td>\n",
       "      <td>font-weight: bold</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes130US</th>\n",
       "      <td></td>\n",
       "      <td>font-weight: bold</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                GMENN                 TE                OHE  \\\n",
       "eucalyptus          font-weight: bold  font-weight: bold                      \n",
       "Midwest_survey                         font-weight: bold  font-weight: bold   \n",
       "hpc-job-scheduling  font-weight: bold  font-weight: bold                      \n",
       "video-game-sales                       font-weight: bold                      \n",
       "okcupid-stem                           font-weight: bold                      \n",
       "Diabetes130US                          font-weight: bold                      \n",
       "\n",
       "                            Embedding             Ignore  \n",
       "eucalyptus          font-weight: bold                     \n",
       "Midwest_survey                                            \n",
       "hpc-job-scheduling  font-weight: bold  font-weight: bold  \n",
       "video-game-sales                                          \n",
       "okcupid-stem                                              \n",
       "Diabetes130US                                             "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.apply(negative_bold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f792cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "{} &        MC-GMENN &            TE &           OHE &     Embedding &        Ignore \\\\\n",
      "\\midrule\n",
      "eucalyptus         &  16.39 (17.547) &   1.3 (0.273) &  1.63 (0.297) &  1.15 (0.132) &  1.57 (0.208) \\\\\n",
      "Midwest\\_survey     &   11.08 (4.698) &  2.85 (0.446) &   3.28 (0.47) &  3.88 (0.398) &  3.45 (0.423) \\\\\n",
      "hpc-job-scheduling &   30.73 (40.96) &  1.82 (0.153) &  3.11 (0.825) &  2.45 (0.664) &   2.2 (0.532) \\\\\n",
      "video-game-sales   &    5.36 (1.804) &  1.71 (0.602) &  6.26 (0.493) &  3.85 (1.098) &   4.7 (1.274) \\\\\n",
      "okcupid-stem       &    8.73 (1.406) &  1.06 (0.121) &  5.31 (0.738) &  2.09 (0.171) &   7.2 (1.358) \\\\\n",
      "Diabetes130US      &   21.97 (7.297) &  1.64 (0.467) &  3.16 (0.543) &  2.11 (0.168) &  6.33 (0.869) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MC-GMENN</th>\n",
       "      <th>TE</th>\n",
       "      <th>OHE</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Ignore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eucalyptus</th>\n",
       "      <td>16.39 (17.547)</td>\n",
       "      <td>1.3 (0.273)</td>\n",
       "      <td>1.63 (0.297)</td>\n",
       "      <td>1.15 (0.132)</td>\n",
       "      <td>1.57 (0.208)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Midwest_survey</th>\n",
       "      <td>11.08 (4.698)</td>\n",
       "      <td>2.85 (0.446)</td>\n",
       "      <td>3.28 (0.47)</td>\n",
       "      <td>3.88 (0.398)</td>\n",
       "      <td>3.45 (0.423)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hpc-job-scheduling</th>\n",
       "      <td>30.73 (40.96)</td>\n",
       "      <td>1.82 (0.153)</td>\n",
       "      <td>3.11 (0.825)</td>\n",
       "      <td>2.45 (0.664)</td>\n",
       "      <td>2.2 (0.532)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video-game-sales</th>\n",
       "      <td>5.36 (1.804)</td>\n",
       "      <td>1.71 (0.602)</td>\n",
       "      <td>6.26 (0.493)</td>\n",
       "      <td>3.85 (1.098)</td>\n",
       "      <td>4.7 (1.274)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>okcupid-stem</th>\n",
       "      <td>8.73 (1.406)</td>\n",
       "      <td>1.06 (0.121)</td>\n",
       "      <td>5.31 (0.738)</td>\n",
       "      <td>2.09 (0.171)</td>\n",
       "      <td>7.2 (1.358)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes130US</th>\n",
       "      <td>21.97 (7.297)</td>\n",
       "      <td>1.64 (0.467)</td>\n",
       "      <td>3.16 (0.543)</td>\n",
       "      <td>2.11 (0.168)</td>\n",
       "      <td>6.33 (0.869)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          MC-GMENN            TE           OHE     Embedding  \\\n",
       "eucalyptus          16.39 (17.547)   1.3 (0.273)  1.63 (0.297)  1.15 (0.132)   \n",
       "Midwest_survey       11.08 (4.698)  2.85 (0.446)   3.28 (0.47)  3.88 (0.398)   \n",
       "hpc-job-scheduling   30.73 (40.96)  1.82 (0.153)  3.11 (0.825)  2.45 (0.664)   \n",
       "video-game-sales      5.36 (1.804)  1.71 (0.602)  6.26 (0.493)  3.85 (1.098)   \n",
       "okcupid-stem          8.73 (1.406)  1.06 (0.121)  5.31 (0.738)  2.09 (0.171)   \n",
       "Diabetes130US        21.97 (7.297)  1.64 (0.467)  3.16 (0.543)  2.11 (0.168)   \n",
       "\n",
       "                          Ignore  \n",
       "eucalyptus          1.57 (0.208)  \n",
       "Midwest_survey      3.45 (0.423)  \n",
       "hpc-job-scheduling   2.2 (0.532)  \n",
       "video-game-sales     4.7 (1.274)  \n",
       "okcupid-stem         7.2 (1.358)  \n",
       "Diabetes130US       6.33 (0.869)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.columns = [\"MC-GMENN\", \"TE\", \"OHE\", \"Embedding\", \"Ignore\"]\n",
    "print(res_df.to_latex(index=True))\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614a5c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cc7bf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMENN        0.21\n",
      "TE           0.92\n",
      "OHE          0.31\n",
      "Embedding    0.51\n",
      "Ignore       0.33\n",
      "dtype: float64\n",
      "GMENN        4.83\n",
      "TE           1.17\n",
      "OHE          3.50\n",
      "Embedding    2.33\n",
      "Ignore       3.17\n",
      "dtype: float64\n",
      "GMENN        897.6621\n",
      "TE             2.2786\n",
      "OHE          147.7971\n",
      "Embedding     53.5333\n",
      "Ignore       186.1027\n",
      "dtype: float64\n",
      "GMENN        14.0079\n",
      "TE            0.0261\n",
      "OHE           2.0885\n",
      "Embedding     0.8829\n",
      "Ignore        2.5362\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eucalyptus</th>\n",
       "      <th>Midwest_survey</th>\n",
       "      <th>hpc-job-scheduling</th>\n",
       "      <th>video-game-sales</th>\n",
       "      <th>okcupid-stem</th>\n",
       "      <th>Diabetes130US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GMENN</th>\n",
       "      <td>16.394967</td>\n",
       "      <td>11.081767</td>\n",
       "      <td>30.734000</td>\n",
       "      <td>5.361667</td>\n",
       "      <td>8.731633</td>\n",
       "      <td>21.970533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TE</th>\n",
       "      <td>1.303432</td>\n",
       "      <td>2.853222</td>\n",
       "      <td>1.816757</td>\n",
       "      <td>1.708940</td>\n",
       "      <td>1.064785</td>\n",
       "      <td>1.636771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OHE</th>\n",
       "      <td>1.630178</td>\n",
       "      <td>3.284085</td>\n",
       "      <td>3.107877</td>\n",
       "      <td>6.263560</td>\n",
       "      <td>5.311045</td>\n",
       "      <td>3.161266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embedding</th>\n",
       "      <td>1.146667</td>\n",
       "      <td>3.883100</td>\n",
       "      <td>2.446967</td>\n",
       "      <td>3.848700</td>\n",
       "      <td>2.092300</td>\n",
       "      <td>2.106633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ignore</th>\n",
       "      <td>1.571267</td>\n",
       "      <td>3.448433</td>\n",
       "      <td>2.199333</td>\n",
       "      <td>4.699400</td>\n",
       "      <td>7.199933</td>\n",
       "      <td>6.326000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           eucalyptus  Midwest_survey  hpc-job-scheduling  video-game-sales  \\\n",
       "GMENN       16.394967       11.081767           30.734000          5.361667   \n",
       "TE           1.303432        2.853222            1.816757          1.708940   \n",
       "OHE          1.630178        3.284085            3.107877          6.263560   \n",
       "Embedding    1.146667        3.883100            2.446967          3.848700   \n",
       "Ignore       1.571267        3.448433            2.199333          4.699400   \n",
       "\n",
       "           okcupid-stem  Diabetes130US  \n",
       "GMENN          8.731633      21.970533  \n",
       "TE             1.064785       1.636771  \n",
       "OHE            5.311045       3.161266  \n",
       "Embedding      2.092300       2.106633  \n",
       "Ignore         7.199933       6.326000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = {}\n",
    "for dataset_name in dataset_names:\n",
    "    dataset_models = list(results_perf[dataset_name][0].keys())\n",
    "    use_df = pd.DataFrame([pd.DataFrame(results_perf[dataset_name][fold_num]).loc[metric,models] for fold_num in results_perf[dataset_name].keys()],index=results_perf[dataset_name].keys())/60\n",
    "    dataset_df[dataset_name] = use_df\n",
    "    \n",
    "mean_df = pd.DataFrame({dataset_name: dataset_df[dataset_name].mean(axis=0) for dataset_name in dataset_names})#*-1\n",
    "\n",
    "# Mean reciprocal rank\n",
    "print(np.mean((1/(mean_df*-1).rank(axis=0,ascending=False)),axis=1).round(2))\n",
    "\n",
    "# Mean rank\n",
    "print(np.mean(((mean_df*-1).rank(axis=0,ascending=False)),axis=1).round(2))\n",
    "\n",
    "# Average distance to best\n",
    "# In %\n",
    "print(mean_df.apply(lambda x: (-100*(np.min(x)-x)/np.min(x)),axis=0).mean(axis=1).round(4))\n",
    "\n",
    "# absolute\n",
    "print(mean_df.apply(lambda x: np.abs(x-np.min(x)),axis=0).mean(axis=1).round(4))\n",
    "\n",
    "mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46370293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "{} &  GMENN &    TE &   OHE &  Embedding &  Ignore \\\\\n",
      "\\midrule\n",
      "0 &   0.21 &  0.92 &  0.31 &       0.51 &    0.33 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(np.mean((1/(-1*mean_df).rank(axis=0,ascending=False)),axis=1).round(2)).transpose().to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d13e21b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "{} &  GMENN &    TE &   OHE &  Embedding &  Ignore \\\\\n",
      "\\midrule\n",
      "0 &  14.01 &  0.03 &  2.09 &       0.88 &    2.54 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(mean_df.apply(lambda x: np.abs(x-np.min(x)),axis=0).mean(axis=1).round(2)).transpose().to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2abc8c",
   "metadata": {},
   "source": [
    "### Learned variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdd3463e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load results for eucalyptus\n",
      "Load results for Midwest_survey\n",
      "Load results for hpc-job-scheduling\n",
      "Load results for video-game-sales\n",
      "Load results for okcupid-stem\n",
      "Load results for Diabetes130US\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(RS)\n",
    "stds_all = {}\n",
    "re_all = {}\n",
    "sig_df_dict = {}\n",
    "z_col_dict = {}\n",
    "\n",
    "for dataset_name in dataset_names:    \n",
    "    stds_all[dataset_name] = {}\n",
    "    re_all[dataset_name] = {}\n",
    "\n",
    "    print(f\"Load results for {dataset_name}\")\n",
    "    data_path = f\"{mode}_RS{RS}_hct{hct}\"\n",
    "    if mode == \"cv\":\n",
    "        data_path += f\"_{folds}folds\"\n",
    "    elif mode == \"train_test\":\n",
    "        data_path += f\"_split{1-test_ratio*100}-{test_ratio*100}\"\n",
    "    elif mode == \"train_val_test\":\n",
    "        data_path += f\"_split{round(100-(test_ratio+val_ratio)*100)}-{round(test_ratio*100)}-{round(val_ratio*100)}\"\n",
    "\n",
    "    with open(f\"../data/prepared/{dataset_name}/{data_path}/data_dict.pickle\", 'rb') as handle:\n",
    "        data_dict = pickle.load(handle)\n",
    "\n",
    "        Z_train = data_dict[f\"Z_train_{fold_num}\"]\n",
    "        Z_val = data_dict[f\"Z_val_{fold_num}\"]\n",
    "        Z_test = data_dict[f\"Z_test_{fold_num}\"]\n",
    "        \n",
    "        y_train = data_dict[f\"y_train_{fold_num}\"]\n",
    "        y_val = data_dict[f\"y_val_{fold_num}\"]\n",
    "        y_test = data_dict[f\"y_test_{fold_num}\"]\n",
    "    \n",
    "        qs = np.max([tf.reduce_max(Z_train, axis=0),tf.reduce_max(Z_val, axis=0),tf.reduce_max(Z_test, axis=0)],axis=0)+1\n",
    "        \n",
    "        \n",
    "    z_col_dict[dataset_name] = [col + f\" (Q={qs[num]})\" for num, col in enumerate(data_dict[\"z_cols\"])]\n",
    "    for fold_num in range(folds):\n",
    "        y_train = data_dict[f\"y_train_{fold_num}\"]\n",
    "\n",
    "        random_effects = results[dataset_name][fold_num][\"other_info\"][\"GMENN\"][\"random_effects\"]\n",
    "        learned_stds = results[dataset_name][fold_num][\"other_info\"][\"GMENN\"][\"_stddev_z\"]**2\n",
    "\n",
    "        stds_all[dataset_name][fold_num] = learned_stds\n",
    "        re_all[dataset_name][fold_num] = random_effects\n",
    "        \n",
    "    df_std_mean = pd.DataFrame(np.array(list(stds_all[dataset_name].values())).mean(axis=0).round(2)).astype(str).transpose()\n",
    "    df_std_std = pd.DataFrame(np.array(list(stds_all[dataset_name].values())).mean(axis=0).round(3)).astype(str).transpose()\n",
    "\n",
    "    sig_df_dict[dataset_name] = df_std_mean+\" (\" + df_std_std + \")\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98f105f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_cols_raw = {\"eucalyptus\": \"Utility\",\n",
    "#               \"Midwest_survey\": \"Location..Census.Region.\",\n",
    "#               \"hpc-job-scheduling\":\"Class\",\n",
    "#               \"video-game-sales\": \"Genre\",\n",
    "#               \"okcupid-stem\": \"job\",\n",
    "#               \"Diabetes130US\": \"readmitted\"}\n",
    "# u,c = np.unique(pd.read_csv(f\"../data/raw/{dataset_name}/{dataset_name}.csv\")[y_cols_raw[dataset_name]],return_counts=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3f1e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latex_df(sig_df_dict,dataset_name):\n",
    "    df_stds = pd.DataFrame(sig_df_dict[dataset_name]).transpose()\n",
    "    df_stds.index=z_col_dict[dataset_name]\n",
    "    df_stds.columns=[f\"$c={i+1}$\" for i in range(sig_df_dict[dataset_name].shape[0])]\n",
    "    return df_stds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc33d7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "{} &         \\$c=1\\$ &         \\$c=2\\$ &         \\$c=3\\$ &         \\$c=4\\$ &         \\$c=5\\$ \\\\\n",
      "\\midrule\n",
      "Abbrev (Q=16)   &  0.01 (0.013) &  0.06 (0.062) &  0.36 (0.358) &   0.0 (0.004) &  0.71 (0.713) \\\\\n",
      "Map\\_Ref (Q=14)  &  0.28 (0.276) &  0.16 (0.165) &  0.02 (0.015) &   0.0 (0.004) &  0.37 (0.366) \\\\\n",
      "Latitude (Q=12) &   0.05 (0.05) &  0.03 (0.026) &  0.02 (0.017) &   0.0 (0.002) &  0.06 (0.055) \\\\\n",
      "Sp (Q=27)       &   0.2 (0.198) &  0.06 (0.062) &   0.02 (0.02) &  0.14 (0.139) &   0.1 (0.095) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$c=1$</th>\n",
       "      <th>$c=2$</th>\n",
       "      <th>$c=3$</th>\n",
       "      <th>$c=4$</th>\n",
       "      <th>$c=5$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abbrev (Q=16)</th>\n",
       "      <td>0.01 (0.013)</td>\n",
       "      <td>0.06 (0.062)</td>\n",
       "      <td>0.36 (0.358)</td>\n",
       "      <td>0.0 (0.004)</td>\n",
       "      <td>0.71 (0.713)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Map_Ref (Q=14)</th>\n",
       "      <td>0.28 (0.276)</td>\n",
       "      <td>0.16 (0.165)</td>\n",
       "      <td>0.02 (0.015)</td>\n",
       "      <td>0.0 (0.004)</td>\n",
       "      <td>0.37 (0.366)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Latitude (Q=12)</th>\n",
       "      <td>0.05 (0.05)</td>\n",
       "      <td>0.03 (0.026)</td>\n",
       "      <td>0.02 (0.017)</td>\n",
       "      <td>0.0 (0.002)</td>\n",
       "      <td>0.06 (0.055)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp (Q=27)</th>\n",
       "      <td>0.2 (0.198)</td>\n",
       "      <td>0.06 (0.062)</td>\n",
       "      <td>0.02 (0.02)</td>\n",
       "      <td>0.14 (0.139)</td>\n",
       "      <td>0.1 (0.095)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        $c=1$         $c=2$         $c=3$         $c=4$  \\\n",
       "Abbrev (Q=16)    0.01 (0.013)  0.06 (0.062)  0.36 (0.358)   0.0 (0.004)   \n",
       "Map_Ref (Q=14)   0.28 (0.276)  0.16 (0.165)  0.02 (0.015)   0.0 (0.004)   \n",
       "Latitude (Q=12)   0.05 (0.05)  0.03 (0.026)  0.02 (0.017)   0.0 (0.002)   \n",
       "Sp (Q=27)         0.2 (0.198)  0.06 (0.062)   0.02 (0.02)  0.14 (0.139)   \n",
       "\n",
       "                        $c=5$  \n",
       "Abbrev (Q=16)    0.71 (0.713)  \n",
       "Map_Ref (Q=14)   0.37 (0.366)  \n",
       "Latitude (Q=12)  0.06 (0.055)  \n",
       "Sp (Q=27)         0.1 (0.095)  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"eucalyptus\"\n",
    "print(get_latex_df(sig_df_dict,dataset_name).to_latex(index=True))\n",
    "get_latex_df(sig_df_dict,dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f746ed8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "{} &        \\$c=1\\$ &        \\$c=2\\$ &         \\$c=3\\$ &         \\$c=4\\$ &         \\$c=5\\$ \\\\\n",
      "\\midrule\n",
      "Question(Q=677) &  2.04 (2.04) &  0.69 (0.69) &  2.18 (2.179) &  3.13 (3.125) &  1.43 (1.428) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "{} &        \\$c=6\\$ &         \\$c=7\\$ &        \\$c=8\\$ &         \\$c=9\\$ &        \\$c=10\\$ \\\\\n",
      "\\midrule\n",
      "Question(Q=677) &  1.0 (0.998) &  3.06 (3.059) &  2.2 (2.197) &  2.65 (2.651) &  3.99 (3.991) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$c=1$</th>\n",
       "      <th>$c=2$</th>\n",
       "      <th>$c=3$</th>\n",
       "      <th>$c=4$</th>\n",
       "      <th>$c=5$</th>\n",
       "      <th>$c=6$</th>\n",
       "      <th>$c=7$</th>\n",
       "      <th>$c=8$</th>\n",
       "      <th>$c=9$</th>\n",
       "      <th>$c=10$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Question(Q=677)</th>\n",
       "      <td>2.04 (2.04)</td>\n",
       "      <td>0.69 (0.69)</td>\n",
       "      <td>2.18 (2.179)</td>\n",
       "      <td>3.13 (3.125)</td>\n",
       "      <td>1.43 (1.428)</td>\n",
       "      <td>1.0 (0.998)</td>\n",
       "      <td>3.06 (3.059)</td>\n",
       "      <td>2.2 (2.197)</td>\n",
       "      <td>2.65 (2.651)</td>\n",
       "      <td>3.99 (3.991)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       $c=1$        $c=2$         $c=3$         $c=4$  \\\n",
       "Question(Q=677)  2.04 (2.04)  0.69 (0.69)  2.18 (2.179)  3.13 (3.125)   \n",
       "\n",
       "                        $c=5$        $c=6$         $c=7$        $c=8$  \\\n",
       "Question(Q=677)  1.43 (1.428)  1.0 (0.998)  3.06 (3.059)  2.2 (2.197)   \n",
       "\n",
       "                        $c=9$        $c=10$  \n",
       "Question(Q=677)  2.65 (2.651)  3.99 (3.991)  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"Midwest_survey\"\n",
    "df_stds = get_latex_df(sig_df_dict,dataset_name)\n",
    "df_stds.index = [\"Question\"+df_stds.index[0].split(\" \")[1]]\n",
    "# pd.concat({dataset_name: pd.DataFrame([df_stds.iloc[:,:5],df_stds.iloc[:,5:]])})\n",
    "print(df_stds.iloc[:,:5].to_latex(index=True))\n",
    "print(df_stds.iloc[:,5:].to_latex(index=True))\n",
    "df_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f13a9286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "{} &         \\$c=1\\$ &         \\$c=2\\$ &         \\$c=3\\$ &         \\$c=4\\$ \\\\\n",
      "\\midrule\n",
      "Protocol (Q=14) &  0.41 (0.411) &  0.51 (0.513) &  0.04 (0.036) &  4.66 (4.662) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$c=1$</th>\n",
       "      <th>$c=2$</th>\n",
       "      <th>$c=3$</th>\n",
       "      <th>$c=4$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Protocol (Q=14)</th>\n",
       "      <td>0.41 (0.411)</td>\n",
       "      <td>0.51 (0.513)</td>\n",
       "      <td>0.04 (0.036)</td>\n",
       "      <td>4.66 (4.662)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        $c=1$         $c=2$         $c=3$         $c=4$\n",
       "Protocol (Q=14)  0.41 (0.411)  0.51 (0.513)  0.04 (0.036)  4.66 (4.662)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"hpc-job-scheduling\"\n",
    "print(get_latex_df(sig_df_dict,dataset_name).to_latex(index=True))\n",
    "get_latex_df(sig_df_dict,dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6c4cf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "{} &         \\$c=1\\$ &         \\$c=2\\$ &         \\$c=3\\$ &         \\$c=4\\$ &         \\$c=5\\$ \\\\\n",
      "\\midrule\n",
      "Platform (Q=32) &  0.44 (0.443) &  0.28 (0.276) &  0.24 (0.235) &  0.29 (0.293) &  0.39 (0.385) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "{} &         \\$c=6\\$ &         \\$c=7\\$ &         \\$c=8\\$ &         \\$c=9\\$ &        \\$c=10\\$ \\\\\n",
      "\\midrule\n",
      "Platform (Q=32) &  0.59 (0.588) &  0.06 (0.064) &  0.15 (0.149) &  0.65 (0.653) &  0.45 (0.445) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "{} &        \\$c=11\\$ &     \\$c=12\\$ \\\\\n",
      "\\midrule\n",
      "Platform (Q=32) &  0.14 (0.139) &  0.5 (0.5) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "{} &         \\$c=1\\$ &         \\$c=2\\$ &         \\$c=3\\$ &        \\$c=4\\$ &         \\$c=5\\$ \\\\\n",
      "\\midrule\n",
      "Publisher (Q=478) &  0.81 (0.815) &  2.33 (2.334) &  1.12 (1.118) &  1.61 (1.61) &  0.73 (0.733) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "{} &        \\$c=6\\$ &         \\$c=7\\$ &         \\$c=8\\$ &         \\$c=9\\$ &       \\$c=10\\$ \\\\\n",
      "\\midrule\n",
      "Publisher (Q=478) &  1.17 (1.17) &  1.34 (1.341) &  2.11 (2.108) &  0.68 (0.683) &  0.91 (0.91) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "{} &        \\$c=11\\$ &        \\$c=12\\$ \\\\\n",
      "\\midrule\n",
      "Publisher (Q=478) &  2.55 (2.545) &  0.91 (0.908) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$c=1$</th>\n",
       "      <th>$c=2$</th>\n",
       "      <th>$c=3$</th>\n",
       "      <th>$c=4$</th>\n",
       "      <th>$c=5$</th>\n",
       "      <th>$c=6$</th>\n",
       "      <th>$c=7$</th>\n",
       "      <th>$c=8$</th>\n",
       "      <th>$c=9$</th>\n",
       "      <th>$c=10$</th>\n",
       "      <th>$c=11$</th>\n",
       "      <th>$c=12$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Platform (Q=32)</th>\n",
       "      <td>0.44 (0.443)</td>\n",
       "      <td>0.28 (0.276)</td>\n",
       "      <td>0.24 (0.235)</td>\n",
       "      <td>0.29 (0.293)</td>\n",
       "      <td>0.39 (0.385)</td>\n",
       "      <td>0.59 (0.588)</td>\n",
       "      <td>0.06 (0.064)</td>\n",
       "      <td>0.15 (0.149)</td>\n",
       "      <td>0.65 (0.653)</td>\n",
       "      <td>0.45 (0.445)</td>\n",
       "      <td>0.14 (0.139)</td>\n",
       "      <td>0.5 (0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Publisher (Q=478)</th>\n",
       "      <td>0.81 (0.815)</td>\n",
       "      <td>2.33 (2.334)</td>\n",
       "      <td>1.12 (1.118)</td>\n",
       "      <td>1.61 (1.61)</td>\n",
       "      <td>0.73 (0.733)</td>\n",
       "      <td>1.17 (1.17)</td>\n",
       "      <td>1.34 (1.341)</td>\n",
       "      <td>2.11 (2.108)</td>\n",
       "      <td>0.68 (0.683)</td>\n",
       "      <td>0.91 (0.91)</td>\n",
       "      <td>2.55 (2.545)</td>\n",
       "      <td>0.91 (0.908)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          $c=1$         $c=2$         $c=3$         $c=4$  \\\n",
       "Platform (Q=32)    0.44 (0.443)  0.28 (0.276)  0.24 (0.235)  0.29 (0.293)   \n",
       "Publisher (Q=478)  0.81 (0.815)  2.33 (2.334)  1.12 (1.118)   1.61 (1.61)   \n",
       "\n",
       "                          $c=5$         $c=6$         $c=7$         $c=8$  \\\n",
       "Platform (Q=32)    0.39 (0.385)  0.59 (0.588)  0.06 (0.064)  0.15 (0.149)   \n",
       "Publisher (Q=478)  0.73 (0.733)   1.17 (1.17)  1.34 (1.341)  2.11 (2.108)   \n",
       "\n",
       "                          $c=9$        $c=10$        $c=11$        $c=12$  \n",
       "Platform (Q=32)    0.65 (0.653)  0.45 (0.445)  0.14 (0.139)     0.5 (0.5)  \n",
       "Publisher (Q=478)  0.68 (0.683)   0.91 (0.91)  2.55 (2.545)  0.91 (0.908)  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"video-game-sales\"\n",
    "df_stds = get_latex_df(sig_df_dict,dataset_name)\n",
    "# pd.concat({dataset_name: pd.DataFrame([df_stds.iloc[:,:5],df_stds.iloc[:,5:]])})\n",
    "print(df_stds.iloc[:1,:5].to_latex(index=True))\n",
    "print(df_stds.iloc[:1,5:10].to_latex(index=True))\n",
    "print(df_stds.iloc[:1,10:].to_latex(index=True))\n",
    "print(df_stds.iloc[1:,:5].to_latex(index=True))\n",
    "print(df_stds.iloc[1:,5:10].to_latex(index=True))\n",
    "print(df_stds.iloc[1:,10:].to_latex(index=True))\n",
    "df_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46fd6c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "{} &         \\$c=1\\$ &         \\$c=2\\$ &         \\$c=3\\$ \\\\\n",
      "\\midrule\n",
      "body\\_type (Q=13)  &  0.03 (0.029) &  0.01 (0.012) &  0.04 (0.045) \\\\\n",
      "diet (Q=19)       &  0.02 (0.021) &  0.02 (0.017) &  0.06 (0.061) \\\\\n",
      "education (Q=33)  &  0.24 (0.241) &   0.8 (0.799) &  3.91 (3.907) \\\\\n",
      "ethnicity (Q=186) &  0.27 (0.265) &  0.27 (0.275) &  0.53 (0.527) \\\\\n",
      "location (Q=149)  &  0.16 (0.164) &  0.17 (0.172) &  0.31 (0.307) \\\\\n",
      "offspring (Q=16)  &  0.01 (0.007) &  0.02 (0.021) &  0.21 (0.206) \\\\\n",
      "pets (Q=16)       &  0.02 (0.024) &  0.08 (0.076) &  0.02 (0.023) \\\\\n",
      "religion (Q=46)   &  0.03 (0.031) &  0.08 (0.079) &  0.06 (0.058) \\\\\n",
      "sign (Q=49)       &  0.02 (0.018) &  0.03 (0.026) &  0.04 (0.039) \\\\\n",
      "speaks (Q=4718)   &  0.81 (0.813) &  0.89 (0.892) &  1.02 (1.024) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$c=1$</th>\n",
       "      <th>$c=2$</th>\n",
       "      <th>$c=3$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>body_type (Q=13)</th>\n",
       "      <td>0.03 (0.029)</td>\n",
       "      <td>0.01 (0.012)</td>\n",
       "      <td>0.04 (0.045)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diet (Q=19)</th>\n",
       "      <td>0.02 (0.021)</td>\n",
       "      <td>0.02 (0.017)</td>\n",
       "      <td>0.06 (0.061)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education (Q=33)</th>\n",
       "      <td>0.24 (0.241)</td>\n",
       "      <td>0.8 (0.799)</td>\n",
       "      <td>3.91 (3.907)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethnicity (Q=186)</th>\n",
       "      <td>0.27 (0.265)</td>\n",
       "      <td>0.27 (0.275)</td>\n",
       "      <td>0.53 (0.527)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location (Q=149)</th>\n",
       "      <td>0.16 (0.164)</td>\n",
       "      <td>0.17 (0.172)</td>\n",
       "      <td>0.31 (0.307)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offspring (Q=16)</th>\n",
       "      <td>0.01 (0.007)</td>\n",
       "      <td>0.02 (0.021)</td>\n",
       "      <td>0.21 (0.206)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pets (Q=16)</th>\n",
       "      <td>0.02 (0.024)</td>\n",
       "      <td>0.08 (0.076)</td>\n",
       "      <td>0.02 (0.023)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>religion (Q=46)</th>\n",
       "      <td>0.03 (0.031)</td>\n",
       "      <td>0.08 (0.079)</td>\n",
       "      <td>0.06 (0.058)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sign (Q=49)</th>\n",
       "      <td>0.02 (0.018)</td>\n",
       "      <td>0.03 (0.026)</td>\n",
       "      <td>0.04 (0.039)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speaks (Q=4718)</th>\n",
       "      <td>0.81 (0.813)</td>\n",
       "      <td>0.89 (0.892)</td>\n",
       "      <td>1.02 (1.024)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          $c=1$         $c=2$         $c=3$\n",
       "body_type (Q=13)   0.03 (0.029)  0.01 (0.012)  0.04 (0.045)\n",
       "diet (Q=19)        0.02 (0.021)  0.02 (0.017)  0.06 (0.061)\n",
       "education (Q=33)   0.24 (0.241)   0.8 (0.799)  3.91 (3.907)\n",
       "ethnicity (Q=186)  0.27 (0.265)  0.27 (0.275)  0.53 (0.527)\n",
       "location (Q=149)   0.16 (0.164)  0.17 (0.172)  0.31 (0.307)\n",
       "offspring (Q=16)   0.01 (0.007)  0.02 (0.021)  0.21 (0.206)\n",
       "pets (Q=16)        0.02 (0.024)  0.08 (0.076)  0.02 (0.023)\n",
       "religion (Q=46)    0.03 (0.031)  0.08 (0.079)  0.06 (0.058)\n",
       "sign (Q=49)        0.02 (0.018)  0.03 (0.026)  0.04 (0.039)\n",
       "speaks (Q=4718)    0.81 (0.813)  0.89 (0.892)  1.02 (1.024)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"okcupid-stem\"\n",
    "print(get_latex_df(sig_df_dict,dataset_name).to_latex(index=True))\n",
    "get_latex_df(sig_df_dict,dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ea257a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "{} &         \\$c=1\\$ &         \\$c=2\\$ &         \\$c=3\\$ \\\\\n",
      "\\midrule\n",
      "age (Q=10)                      &   0.0 (0.003) &   0.0 (0.002) &     0.0 (0.0) \\\\\n",
      "discharge\\_disposition\\_id (Q=26) &  2.57 (2.569) &   1.0 (1.005) &  0.13 (0.131) \\\\\n",
      "admission\\_source\\_id (Q=17)      &  0.06 (0.064) &  0.05 (0.047) &  0.14 (0.137) \\\\\n",
      "payer\\_code (Q=19)               &  0.03 (0.032) &  0.01 (0.007) &   0.0 (0.002) \\\\\n",
      "medical\\_specialty (Q=71)        &  0.02 (0.025) &   0.04 (0.04) &   0.02 (0.02) \\\\\n",
      "diag\\_1 (Q=674)                  &  0.06 (0.062) &  0.12 (0.118) &  0.06 (0.061) \\\\\n",
      "diag\\_2 (Q=684)                  &  0.06 (0.058) &  0.09 (0.088) &   0.06 (0.06) \\\\\n",
      "diag\\_3 (Q=732)                  &  0.06 (0.064) &  0.08 (0.082) &  0.06 (0.058) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$c=1$</th>\n",
       "      <th>$c=2$</th>\n",
       "      <th>$c=3$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age (Q=10)</th>\n",
       "      <td>0.0 (0.003)</td>\n",
       "      <td>0.0 (0.002)</td>\n",
       "      <td>0.0 (0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discharge_disposition_id (Q=26)</th>\n",
       "      <td>2.57 (2.569)</td>\n",
       "      <td>1.0 (1.005)</td>\n",
       "      <td>0.13 (0.131)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admission_source_id (Q=17)</th>\n",
       "      <td>0.06 (0.064)</td>\n",
       "      <td>0.05 (0.047)</td>\n",
       "      <td>0.14 (0.137)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payer_code (Q=19)</th>\n",
       "      <td>0.03 (0.032)</td>\n",
       "      <td>0.01 (0.007)</td>\n",
       "      <td>0.0 (0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_specialty (Q=71)</th>\n",
       "      <td>0.02 (0.025)</td>\n",
       "      <td>0.04 (0.04)</td>\n",
       "      <td>0.02 (0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diag_1 (Q=674)</th>\n",
       "      <td>0.06 (0.062)</td>\n",
       "      <td>0.12 (0.118)</td>\n",
       "      <td>0.06 (0.061)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diag_2 (Q=684)</th>\n",
       "      <td>0.06 (0.058)</td>\n",
       "      <td>0.09 (0.088)</td>\n",
       "      <td>0.06 (0.06)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diag_3 (Q=732)</th>\n",
       "      <td>0.06 (0.064)</td>\n",
       "      <td>0.08 (0.082)</td>\n",
       "      <td>0.06 (0.058)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        $c=1$         $c=2$         $c=3$\n",
       "age (Q=10)                        0.0 (0.003)   0.0 (0.002)     0.0 (0.0)\n",
       "discharge_disposition_id (Q=26)  2.57 (2.569)   1.0 (1.005)  0.13 (0.131)\n",
       "admission_source_id (Q=17)       0.06 (0.064)  0.05 (0.047)  0.14 (0.137)\n",
       "payer_code (Q=19)                0.03 (0.032)  0.01 (0.007)   0.0 (0.002)\n",
       "medical_specialty (Q=71)         0.02 (0.025)   0.04 (0.04)   0.02 (0.02)\n",
       "diag_1 (Q=674)                   0.06 (0.062)  0.12 (0.118)  0.06 (0.061)\n",
       "diag_2 (Q=684)                   0.06 (0.058)  0.09 (0.088)   0.06 (0.06)\n",
       "diag_3 (Q=732)                   0.06 (0.064)  0.08 (0.082)  0.06 (0.058)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"Diabetes130US\"\n",
    "print(get_latex_df(sig_df_dict,dataset_name).to_latex(index=True))\n",
    "get_latex_df(sig_df_dict,dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203310dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gmenn",
   "language": "python",
   "name": "gmenn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc07112e7ae1e8e28a0232207620ff002934c05692de8df42430404c766a0a8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
